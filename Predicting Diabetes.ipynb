{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "3         1            89            66         23       94  28.1      0.167   \n",
       "4         0           137            40         35      168  43.1      2.288   \n",
       "\n",
       "   age    skin  diabetes  \n",
       "0   50  1.3790      True  \n",
       "1   31  1.1426     False  \n",
       "2   32  0.0000      True  \n",
       "3   21  0.9062     False  \n",
       "4   33  1.3790      True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Contents\\\\Txt\\MachineLearningWithPython-master\\\\MachineLearningWithPython-master\\\\Notebooks\\\\data\\\\pima-data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "plt.figure(figsize= (12,12))\n",
    "sb.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['skin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].isnull().values.any():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_map = {True : 1, False :0}\n",
    "df['diabetes'] = df['diabetes'].map(diabetes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "3         1            89            66         23       94  28.1      0.167   \n",
       "4         0           137            40         35      168  43.1      2.288   \n",
       "\n",
       "   age  diabetes  \n",
       "0   50         1  \n",
       "1   31         0  \n",
       "2   32         1  \n",
       "3   21         0  \n",
       "4   33         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin', 'bmi', 'diab_pred', 'age']\n",
    "predicted_class_names = ['diabetes']\n",
    "\n",
    "X = df[feature_col_names].values\n",
    "Y = df[predicted_class_names].values\n",
    "split_test_size = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=split_test_size, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,  input_dim=8, init= 'uniform', activation = \"relu\"))\n",
    "model.add(Dense(8,  init= 'uniform', activation = \"relu\"))\n",
    "model.add(Dense(1,   init= 'uniform', activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.6787 - accuracy: 0.6499 - val_loss: 0.6619 - val_accuracy: 0.6537\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.6658 - accuracy: 0.6499 - val_loss: 0.6553 - val_accuracy: 0.6537\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.6595 - accuracy: 0.6499 - val_loss: 0.6486 - val_accuracy: 0.6537\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.6509 - accuracy: 0.6499 - val_loss: 0.6368 - val_accuracy: 0.6537\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 304us/step - loss: 0.6410 - accuracy: 0.6499 - val_loss: 0.6303 - val_accuracy: 0.6537\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.6292 - accuracy: 0.6499 - val_loss: 0.6219 - val_accuracy: 0.6537\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 305us/step - loss: 0.6204 - accuracy: 0.6499 - val_loss: 0.6160 - val_accuracy: 0.6537\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.6149 - accuracy: 0.6499 - val_loss: 0.6119 - val_accuracy: 0.6537\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 269us/step - loss: 0.6130 - accuracy: 0.6499 - val_loss: 0.6136 - val_accuracy: 0.6537\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.6105 - accuracy: 0.6499 - val_loss: 0.6119 - val_accuracy: 0.6537\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.6090 - accuracy: 0.6499 - val_loss: 0.6108 - val_accuracy: 0.6537\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 326us/step - loss: 0.6007 - accuracy: 0.6499 - val_loss: 0.6115 - val_accuracy: 0.6537\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.6041 - accuracy: 0.6499 - val_loss: 0.6054 - val_accuracy: 0.6537\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 325us/step - loss: 0.6021 - accuracy: 0.6499 - val_loss: 0.6171 - val_accuracy: 0.6537\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.6144 - accuracy: 0.6499 - val_loss: 0.6047 - val_accuracy: 0.6537\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.5977 - accuracy: 0.6499 - val_loss: 0.6009 - val_accuracy: 0.6537\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 308us/step - loss: 0.5990 - accuracy: 0.6499 - val_loss: 0.6015 - val_accuracy: 0.6537\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.5974 - accuracy: 0.6499 - val_loss: 0.6082 - val_accuracy: 0.6537\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 250us/step - loss: 0.6000 - accuracy: 0.6499 - val_loss: 0.6032 - val_accuracy: 0.6537\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5930 - accuracy: 0.6499 - val_loss: 0.6208 - val_accuracy: 0.6537\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s 279us/step - loss: 0.6035 - accuracy: 0.6499 - val_loss: 0.6038 - val_accuracy: 0.6537\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 323us/step - loss: 0.5946 - accuracy: 0.6499 - val_loss: 0.6102 - val_accuracy: 0.6537\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 292us/step - loss: 0.5982 - accuracy: 0.6499 - val_loss: 0.6010 - val_accuracy: 0.6494\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 305us/step - loss: 0.5912 - accuracy: 0.6648 - val_loss: 0.6006 - val_accuracy: 0.6537\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s 305us/step - loss: 0.5875 - accuracy: 0.6518 - val_loss: 0.6011 - val_accuracy: 0.6580\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5909 - accuracy: 0.6723 - val_loss: 0.6006 - val_accuracy: 0.7013\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5863 - accuracy: 0.6741 - val_loss: 0.5984 - val_accuracy: 0.6623\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.5852 - accuracy: 0.6592 - val_loss: 0.5999 - val_accuracy: 0.6926\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.5869 - accuracy: 0.6667 - val_loss: 0.6003 - val_accuracy: 0.6710\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 303us/step - loss: 0.5847 - accuracy: 0.6723 - val_loss: 0.5959 - val_accuracy: 0.6840\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.5812 - accuracy: 0.6778 - val_loss: 0.5967 - val_accuracy: 0.7100\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.5768 - accuracy: 0.6778 - val_loss: 0.6027 - val_accuracy: 0.6710\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 298us/step - loss: 0.5807 - accuracy: 0.6592 - val_loss: 0.5936 - val_accuracy: 0.6753\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5822 - accuracy: 0.6797 - val_loss: 0.6162 - val_accuracy: 0.6926\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5779 - accuracy: 0.6909 - val_loss: 0.5938 - val_accuracy: 0.6753\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 245us/step - loss: 0.5793 - accuracy: 0.6760 - val_loss: 0.5950 - val_accuracy: 0.6753\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5778 - accuracy: 0.6667 - val_loss: 0.5971 - val_accuracy: 0.6883\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5735 - accuracy: 0.6872 - val_loss: 0.6151 - val_accuracy: 0.7013\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5806 - accuracy: 0.6797 - val_loss: 0.5959 - val_accuracy: 0.7056\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 308us/step - loss: 0.5765 - accuracy: 0.6834 - val_loss: 0.5939 - val_accuracy: 0.6883\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 314us/step - loss: 0.5743 - accuracy: 0.6853 - val_loss: 0.5984 - val_accuracy: 0.7013\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.5800 - accuracy: 0.6816 - val_loss: 0.5948 - val_accuracy: 0.6840\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 328us/step - loss: 0.5719 - accuracy: 0.6872 - val_loss: 0.6051 - val_accuracy: 0.6883\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.5787 - accuracy: 0.6778 - val_loss: 0.5970 - val_accuracy: 0.6970\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5816 - accuracy: 0.6797 - val_loss: 0.5911 - val_accuracy: 0.6926\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5706 - accuracy: 0.6946 - val_loss: 0.6012 - val_accuracy: 0.6970\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 279us/step - loss: 0.5763 - accuracy: 0.6890 - val_loss: 0.5921 - val_accuracy: 0.6840\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.5713 - accuracy: 0.6816 - val_loss: 0.5958 - val_accuracy: 0.6926\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.5700 - accuracy: 0.6797 - val_loss: 0.5946 - val_accuracy: 0.6840\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5664 - accuracy: 0.6872 - val_loss: 0.5954 - val_accuracy: 0.6926\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 303us/step - loss: 0.5651 - accuracy: 0.6946 - val_loss: 0.5962 - val_accuracy: 0.6970\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.5733 - accuracy: 0.6834 - val_loss: 0.6028 - val_accuracy: 0.6926\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 305us/step - loss: 0.5717 - accuracy: 0.6816 - val_loss: 0.5898 - val_accuracy: 0.7013\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5679 - accuracy: 0.6872 - val_loss: 0.6009 - val_accuracy: 0.6970\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.5730 - accuracy: 0.6853 - val_loss: 0.5957 - val_accuracy: 0.6797\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5625 - accuracy: 0.6946 - val_loss: 0.5924 - val_accuracy: 0.6883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s 306us/step - loss: 0.5641 - accuracy: 0.6834 - val_loss: 0.5952 - val_accuracy: 0.7056\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 306us/step - loss: 0.5653 - accuracy: 0.6946 - val_loss: 0.5926 - val_accuracy: 0.6926\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 306us/step - loss: 0.5641 - accuracy: 0.6946 - val_loss: 0.5925 - val_accuracy: 0.6970\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.5604 - accuracy: 0.6853 - val_loss: 0.5982 - val_accuracy: 0.6926\n",
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5630 - accuracy: 0.6853 - val_loss: 0.5907 - val_accuracy: 0.6970\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 317us/step - loss: 0.5625 - accuracy: 0.6965 - val_loss: 0.5916 - val_accuracy: 0.6926\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 322us/step - loss: 0.5580 - accuracy: 0.6872 - val_loss: 0.5937 - val_accuracy: 0.6926\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 331us/step - loss: 0.5594 - accuracy: 0.6927 - val_loss: 0.5939 - val_accuracy: 0.6840\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5531 - accuracy: 0.6834 - val_loss: 0.5958 - val_accuracy: 0.6970\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 300us/step - loss: 0.5589 - accuracy: 0.6965 - val_loss: 0.6057 - val_accuracy: 0.6883\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 324us/step - loss: 0.5583 - accuracy: 0.6965 - val_loss: 0.5943 - val_accuracy: 0.7013\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 235us/step - loss: 0.5559 - accuracy: 0.6909 - val_loss: 0.6001 - val_accuracy: 0.6753\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5567 - accuracy: 0.6853 - val_loss: 0.6038 - val_accuracy: 0.6840\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5586 - accuracy: 0.6741 - val_loss: 0.6047 - val_accuracy: 0.6797\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5530 - accuracy: 0.7002 - val_loss: 0.5953 - val_accuracy: 0.6970\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 300us/step - loss: 0.5521 - accuracy: 0.6909 - val_loss: 0.5973 - val_accuracy: 0.6840\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5543 - accuracy: 0.6965 - val_loss: 0.5937 - val_accuracy: 0.7056\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 300us/step - loss: 0.5464 - accuracy: 0.7039 - val_loss: 0.5985 - val_accuracy: 0.6753\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5516 - accuracy: 0.6872 - val_loss: 0.5882 - val_accuracy: 0.6840\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5564 - accuracy: 0.6853 - val_loss: 0.5933 - val_accuracy: 0.6883\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 317us/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.5914 - val_accuracy: 0.7013\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5531 - accuracy: 0.6890 - val_loss: 0.5918 - val_accuracy: 0.6926\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 174us/step - loss: 0.5539 - accuracy: 0.6890 - val_loss: 0.6106 - val_accuracy: 0.6797\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 263us/step - loss: 0.5557 - accuracy: 0.6927 - val_loss: 0.5921 - val_accuracy: 0.6926\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 327us/step - loss: 0.5470 - accuracy: 0.6927 - val_loss: 0.5921 - val_accuracy: 0.6970\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 306us/step - loss: 0.5441 - accuracy: 0.6816 - val_loss: 0.5934 - val_accuracy: 0.6883\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 308us/step - loss: 0.5471 - accuracy: 0.6946 - val_loss: 0.5868 - val_accuracy: 0.6926\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.5503 - accuracy: 0.6983 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5581 - accuracy: 0.6890 - val_loss: 0.5953 - val_accuracy: 0.6926\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5407 - accuracy: 0.6965 - val_loss: 0.5933 - val_accuracy: 0.6840\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5461 - accuracy: 0.6946 - val_loss: 0.6019 - val_accuracy: 0.6753\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.5411 - accuracy: 0.7076 - val_loss: 0.5892 - val_accuracy: 0.6970\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 264us/step - loss: 0.5383 - accuracy: 0.7002 - val_loss: 0.5968 - val_accuracy: 0.6710\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5427 - accuracy: 0.6946 - val_loss: 0.5870 - val_accuracy: 0.6926\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 328us/step - loss: 0.5333 - accuracy: 0.6946 - val_loss: 0.5912 - val_accuracy: 0.6883\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.5464 - accuracy: 0.6890 - val_loss: 0.5873 - val_accuracy: 0.6926\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5355 - accuracy: 0.6927 - val_loss: 0.6182 - val_accuracy: 0.6883\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.5460 - accuracy: 0.7002 - val_loss: 0.5944 - val_accuracy: 0.6710\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5344 - accuracy: 0.7002 - val_loss: 0.5898 - val_accuracy: 0.6840\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.5404 - accuracy: 0.6853 - val_loss: 0.5939 - val_accuracy: 0.6970\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.5366 - accuracy: 0.7076 - val_loss: 0.5915 - val_accuracy: 0.7013\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.5395 - accuracy: 0.7002 - val_loss: 0.5911 - val_accuracy: 0.6926\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5337 - accuracy: 0.6909 - val_loss: 0.5936 - val_accuracy: 0.6840\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5456 - accuracy: 0.6741 - val_loss: 0.5947 - val_accuracy: 0.6797\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 306us/step - loss: 0.5314 - accuracy: 0.6927 - val_loss: 0.5873 - val_accuracy: 0.6840\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5309 - accuracy: 0.7039 - val_loss: 0.5878 - val_accuracy: 0.6883\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.5386 - accuracy: 0.6909 - val_loss: 0.5889 - val_accuracy: 0.7013\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 311us/step - loss: 0.5328 - accuracy: 0.6872 - val_loss: 0.5825 - val_accuracy: 0.6840\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5282 - accuracy: 0.6965 - val_loss: 0.6100 - val_accuracy: 0.6623\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 316us/step - loss: 0.5278 - accuracy: 0.6965 - val_loss: 0.5868 - val_accuracy: 0.6926\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.5315 - accuracy: 0.6890 - val_loss: 0.5880 - val_accuracy: 0.6883\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5337 - accuracy: 0.7020 - val_loss: 0.5877 - val_accuracy: 0.6883\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.5309 - accuracy: 0.6965 - val_loss: 0.5819 - val_accuracy: 0.7013\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.5298 - accuracy: 0.7020 - val_loss: 0.5771 - val_accuracy: 0.6926\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.5211 - accuracy: 0.6965 - val_loss: 0.5909 - val_accuracy: 0.6667\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.5189 - accuracy: 0.7244 - val_loss: 0.5788 - val_accuracy: 0.6926\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 298us/step - loss: 0.5176 - accuracy: 0.7356 - val_loss: 0.5779 - val_accuracy: 0.6970\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.5245 - accuracy: 0.7188 - val_loss: 0.5880 - val_accuracy: 0.7056\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 321us/step - loss: 0.5194 - accuracy: 0.7263 - val_loss: 0.5853 - val_accuracy: 0.6926\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.5166 - accuracy: 0.7188 - val_loss: 0.5648 - val_accuracy: 0.7273\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 317us/step - loss: 0.5059 - accuracy: 0.7430 - val_loss: 0.5704 - val_accuracy: 0.7143\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.5047 - accuracy: 0.7393 - val_loss: 0.5663 - val_accuracy: 0.7273\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.4992 - accuracy: 0.7579 - val_loss: 0.5700 - val_accuracy: 0.7186\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5884 - val_accuracy: 0.7056\n",
      "Epoch 121/150\n",
      "537/537 [==============================] - 0s 314us/step - loss: 0.5084 - accuracy: 0.7505 - val_loss: 0.5705 - val_accuracy: 0.7186\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 314us/step - loss: 0.4959 - accuracy: 0.7523 - val_loss: 0.5822 - val_accuracy: 0.6970\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 319us/step - loss: 0.5008 - accuracy: 0.7430 - val_loss: 0.5653 - val_accuracy: 0.7229\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.5026 - accuracy: 0.7337 - val_loss: 0.5649 - val_accuracy: 0.7273\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.74 - 0s 321us/step - loss: 0.4969 - accuracy: 0.7374 - val_loss: 0.5834 - val_accuracy: 0.6883\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.4982 - accuracy: 0.7430 - val_loss: 0.5921 - val_accuracy: 0.6926\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 325us/step - loss: 0.5107 - accuracy: 0.7356 - val_loss: 0.5654 - val_accuracy: 0.7229\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 324us/step - loss: 0.4916 - accuracy: 0.7486 - val_loss: 0.5608 - val_accuracy: 0.7359\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 317us/step - loss: 0.4942 - accuracy: 0.7561 - val_loss: 0.5727 - val_accuracy: 0.7186\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.4930 - accuracy: 0.7542 - val_loss: 0.5840 - val_accuracy: 0.7229\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 308us/step - loss: 0.4978 - accuracy: 0.7486 - val_loss: 0.5671 - val_accuracy: 0.7446\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.4900 - accuracy: 0.7542 - val_loss: 0.5745 - val_accuracy: 0.7273\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 319us/step - loss: 0.4902 - accuracy: 0.7467 - val_loss: 0.5730 - val_accuracy: 0.7100\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 317us/step - loss: 0.4868 - accuracy: 0.7598 - val_loss: 0.5561 - val_accuracy: 0.7359\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 314us/step - loss: 0.4835 - accuracy: 0.7561 - val_loss: 0.5702 - val_accuracy: 0.7273\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.4890 - accuracy: 0.7542 - val_loss: 0.5795 - val_accuracy: 0.7100\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 310us/step - loss: 0.4787 - accuracy: 0.7616 - val_loss: 0.5610 - val_accuracy: 0.7273\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 305us/step - loss: 0.4835 - accuracy: 0.7672 - val_loss: 0.5619 - val_accuracy: 0.7403\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.4853 - accuracy: 0.7542 - val_loss: 0.5580 - val_accuracy: 0.7359\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 313us/step - loss: 0.4797 - accuracy: 0.7598 - val_loss: 0.5581 - val_accuracy: 0.7532\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.4815 - accuracy: 0.7598 - val_loss: 0.5611 - val_accuracy: 0.7143\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 318us/step - loss: 0.4766 - accuracy: 0.7579 - val_loss: 0.5707 - val_accuracy: 0.7186\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 303us/step - loss: 0.4804 - accuracy: 0.7561 - val_loss: 0.5677 - val_accuracy: 0.7273\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 315us/step - loss: 0.4737 - accuracy: 0.7709 - val_loss: 0.5907 - val_accuracy: 0.7013\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.4824 - accuracy: 0.7561 - val_loss: 0.5923 - val_accuracy: 0.6926\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.4785 - accuracy: 0.7654 - val_loss: 0.5678 - val_accuracy: 0.7056\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.4828 - accuracy: 0.7579 - val_loss: 0.5923 - val_accuracy: 0.7013\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 309us/step - loss: 0.4843 - accuracy: 0.7635 - val_loss: 0.5753 - val_accuracy: 0.6970\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.4729 - accuracy: 0.7616 - val_loss: 0.5752 - val_accuracy: 0.6970\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 319us/step - loss: 0.4733 - accuracy: 0.7598 - val_loss: 0.5626 - val_accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238fbd39ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=150,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7672 - val_loss: 0.5569 - val_accuracy: 0.7316\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.4621 - accuracy: 0.7784 - val_loss: 0.5579 - val_accuracy: 0.7359\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4610 - accuracy: 0.7747 - val_loss: 0.5538 - val_accuracy: 0.7489\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.4580 - accuracy: 0.7709 - val_loss: 0.5570 - val_accuracy: 0.7316\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.4604 - accuracy: 0.7821 - val_loss: 0.5659 - val_accuracy: 0.7359\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4629 - accuracy: 0.7765 - val_loss: 0.5603 - val_accuracy: 0.7229\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.4556 - accuracy: 0.7709 - val_loss: 0.5559 - val_accuracy: 0.7316\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4553 - accuracy: 0.7765 - val_loss: 0.5560 - val_accuracy: 0.7532\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.4574 - accuracy: 0.7803 - val_loss: 0.5573 - val_accuracy: 0.7316\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4523 - accuracy: 0.7709 - val_loss: 0.5627 - val_accuracy: 0.7143\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.4523 - accuracy: 0.7821 - val_loss: 0.5548 - val_accuracy: 0.7359\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4528 - accuracy: 0.7765 - val_loss: 0.5571 - val_accuracy: 0.7186\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.4542 - accuracy: 0.7784 - val_loss: 0.5481 - val_accuracy: 0.7576\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4513 - accuracy: 0.7840 - val_loss: 0.5540 - val_accuracy: 0.7273\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4474 - accuracy: 0.7803 - val_loss: 0.5537 - val_accuracy: 0.7403\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.4505 - accuracy: 0.7877 - val_loss: 0.5627 - val_accuracy: 0.7229\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.4574 - accuracy: 0.7877 - val_loss: 0.5640 - val_accuracy: 0.7403\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.4463 - accuracy: 0.7803 - val_loss: 0.5551 - val_accuracy: 0.7186\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.4477 - accuracy: 0.7821 - val_loss: 0.5516 - val_accuracy: 0.7229\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.4455 - accuracy: 0.7840 - val_loss: 0.5524 - val_accuracy: 0.7446\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4485 - accuracy: 0.7858 - val_loss: 0.5522 - val_accuracy: 0.7229\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.4470 - accuracy: 0.7747 - val_loss: 0.5630 - val_accuracy: 0.7316\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4480 - accuracy: 0.7803 - val_loss: 0.5513 - val_accuracy: 0.7229\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.4429 - accuracy: 0.7877 - val_loss: 0.5528 - val_accuracy: 0.7056\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4450 - accuracy: 0.7896 - val_loss: 0.5495 - val_accuracy: 0.7532\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.4420 - accuracy: 0.7914 - val_loss: 0.5586 - val_accuracy: 0.6926\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4386 - accuracy: 0.7914 - val_loss: 0.5505 - val_accuracy: 0.7273\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4403 - accuracy: 0.7914 - val_loss: 0.5556 - val_accuracy: 0.7403\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.4500 - accuracy: 0.7914 - val_loss: 0.5505 - val_accuracy: 0.7359\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4363 - accuracy: 0.7821 - val_loss: 0.5454 - val_accuracy: 0.7403\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.4364 - accuracy: 0.7877 - val_loss: 0.5491 - val_accuracy: 0.7229\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.4362 - accuracy: 0.7877 - val_loss: 0.5582 - val_accuracy: 0.7273\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4431 - accuracy: 0.7952 - val_loss: 0.5684 - val_accuracy: 0.7316\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4356 - accuracy: 0.7858 - val_loss: 0.5495 - val_accuracy: 0.7359\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4335 - accuracy: 0.7914 - val_loss: 0.5489 - val_accuracy: 0.7446\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4357 - accuracy: 0.7970 - val_loss: 0.5474 - val_accuracy: 0.7359\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.4345 - accuracy: 0.7933 - val_loss: 0.5435 - val_accuracy: 0.7576\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.4311 - accuracy: 0.7840 - val_loss: 0.5498 - val_accuracy: 0.7229\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.4377 - accuracy: 0.7765 - val_loss: 0.5614 - val_accuracy: 0.7359\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4310 - accuracy: 0.8007 - val_loss: 0.5669 - val_accuracy: 0.7359\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.4334 - accuracy: 0.7877 - val_loss: 0.5466 - val_accuracy: 0.7229\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4292 - accuracy: 0.7933 - val_loss: 0.5466 - val_accuracy: 0.7273\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.4279 - accuracy: 0.7970 - val_loss: 0.5509 - val_accuracy: 0.7186\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4305 - accuracy: 0.7933 - val_loss: 0.5514 - val_accuracy: 0.7316\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.4342 - accuracy: 0.7877 - val_loss: 0.5424 - val_accuracy: 0.7359\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.4261 - accuracy: 0.7989 - val_loss: 0.5484 - val_accuracy: 0.7316\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.4264 - accuracy: 0.7952 - val_loss: 0.5500 - val_accuracy: 0.7359\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.4264 - accuracy: 0.7877 - val_loss: 0.5450 - val_accuracy: 0.7316\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.4219 - accuracy: 0.7952 - val_loss: 0.5553 - val_accuracy: 0.7186\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.4281 - accuracy: 0.7989 - val_loss: 0.5571 - val_accuracy: 0.7273\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.4229 - accuracy: 0.8045 - val_loss: 0.5488 - val_accuracy: 0.7359\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.4186 - accuracy: 0.7989 - val_loss: 0.5507 - val_accuracy: 0.7143\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.4247 - accuracy: 0.7896 - val_loss: 0.5707 - val_accuracy: 0.7446\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.4290 - accuracy: 0.7989 - val_loss: 0.5430 - val_accuracy: 0.7489\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.4170 - accuracy: 0.8045 - val_loss: 0.5479 - val_accuracy: 0.7273\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.4210 - accuracy: 0.7952 - val_loss: 0.5515 - val_accuracy: 0.7489\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 90us/step - loss: 0.4250 - accuracy: 0.7933 - val_loss: 0.5619 - val_accuracy: 0.7186\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.4260 - accuracy: 0.7970 - val_loss: 0.5539 - val_accuracy: 0.7273\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.4189 - accuracy: 0.7933 - val_loss: 0.5585 - val_accuracy: 0.7316\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.4175 - accuracy: 0.7952 - val_loss: 0.5596 - val_accuracy: 0.7316\n",
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4118 - accuracy: 0.7970 - val_loss: 0.5510 - val_accuracy: 0.7446\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.4141 - accuracy: 0.8026 - val_loss: 0.5629 - val_accuracy: 0.7100\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4188 - accuracy: 0.7765 - val_loss: 0.5500 - val_accuracy: 0.7273\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.4166 - accuracy: 0.8101 - val_loss: 0.5638 - val_accuracy: 0.7273\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.4144 - accuracy: 0.7952 - val_loss: 0.5536 - val_accuracy: 0.7316\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4154 - accuracy: 0.8082 - val_loss: 0.5633 - val_accuracy: 0.7143\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.4190 - accuracy: 0.7933 - val_loss: 0.5677 - val_accuracy: 0.7403\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.4151 - accuracy: 0.7970 - val_loss: 0.5544 - val_accuracy: 0.7316\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.4135 - accuracy: 0.7989 - val_loss: 0.5652 - val_accuracy: 0.7403\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4149 - accuracy: 0.7896 - val_loss: 0.5572 - val_accuracy: 0.7186\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.4110 - accuracy: 0.8026 - val_loss: 0.5628 - val_accuracy: 0.7229\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4137 - accuracy: 0.7914 - val_loss: 0.5575 - val_accuracy: 0.7316\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4097 - accuracy: 0.8026 - val_loss: 0.5629 - val_accuracy: 0.7229\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.4066 - accuracy: 0.8007 - val_loss: 0.5572 - val_accuracy: 0.7316\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.4058 - accuracy: 0.7989 - val_loss: 0.5706 - val_accuracy: 0.7143\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.4107 - accuracy: 0.8026 - val_loss: 0.5606 - val_accuracy: 0.7229\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4092 - accuracy: 0.8007 - val_loss: 0.5710 - val_accuracy: 0.7186\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4105 - accuracy: 0.7970 - val_loss: 0.5674 - val_accuracy: 0.7316\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4137 - accuracy: 0.7989 - val_loss: 0.5665 - val_accuracy: 0.7186\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.4102 - accuracy: 0.7989 - val_loss: 0.5633 - val_accuracy: 0.7576\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4152 - accuracy: 0.7933 - val_loss: 0.5656 - val_accuracy: 0.7273\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.4039 - accuracy: 0.7989 - val_loss: 0.5640 - val_accuracy: 0.7229\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4005 - accuracy: 0.8082 - val_loss: 0.5745 - val_accuracy: 0.7359\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.4116 - accuracy: 0.7877 - val_loss: 0.5701 - val_accuracy: 0.7100\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4101 - accuracy: 0.7970 - val_loss: 0.5703 - val_accuracy: 0.7273\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.7933 - val_loss: 0.5679 - val_accuracy: 0.7229\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.4010 - accuracy: 0.7877 - val_loss: 0.5659 - val_accuracy: 0.7403\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4028 - accuracy: 0.7989 - val_loss: 0.5715 - val_accuracy: 0.7143\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.4037 - accuracy: 0.7933 - val_loss: 0.5668 - val_accuracy: 0.7532\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.4062 - accuracy: 0.7952 - val_loss: 0.5777 - val_accuracy: 0.7143\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.4052 - accuracy: 0.7914 - val_loss: 0.5662 - val_accuracy: 0.7316\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.4034 - accuracy: 0.7896 - val_loss: 0.5642 - val_accuracy: 0.7359\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.4038 - accuracy: 0.8045 - val_loss: 0.5695 - val_accuracy: 0.7229\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4044 - accuracy: 0.7896 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4048 - accuracy: 0.7952 - val_loss: 0.5786 - val_accuracy: 0.7229\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.71 - 0s 101us/step - loss: 0.4043 - accuracy: 0.7952 - val_loss: 0.5686 - val_accuracy: 0.7316\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.4106 - accuracy: 0.7933 - val_loss: 0.5702 - val_accuracy: 0.7229\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.4110 - accuracy: 0.7821 - val_loss: 0.5784 - val_accuracy: 0.7316\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.4006 - accuracy: 0.7952 - val_loss: 0.5691 - val_accuracy: 0.7100\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.4046 - accuracy: 0.7933 - val_loss: 0.5683 - val_accuracy: 0.7229\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.4015 - accuracy: 0.7877 - val_loss: 0.5777 - val_accuracy: 0.7316\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.3935 - accuracy: 0.7970 - val_loss: 0.5631 - val_accuracy: 0.7186\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.3980 - accuracy: 0.7989 - val_loss: 0.5684 - val_accuracy: 0.7273\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.4001 - accuracy: 0.7914 - val_loss: 0.5715 - val_accuracy: 0.7273\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.4044 - accuracy: 0.7933 - val_loss: 0.5668 - val_accuracy: 0.7229\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.3972 - accuracy: 0.7989 - val_loss: 0.5622 - val_accuracy: 0.7186\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.3957 - accuracy: 0.8045 - val_loss: 0.5727 - val_accuracy: 0.7143\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.3947 - accuracy: 0.7989 - val_loss: 0.5679 - val_accuracy: 0.7100\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.4038 - accuracy: 0.7952 - val_loss: 0.5735 - val_accuracy: 0.7316\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 110us/step - loss: 0.4007 - accuracy: 0.7952 - val_loss: 0.5765 - val_accuracy: 0.7013\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.3945 - accuracy: 0.8026 - val_loss: 0.5640 - val_accuracy: 0.7316\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.3934 - accuracy: 0.8026 - val_loss: 0.5728 - val_accuracy: 0.7359\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 85us/step - loss: 0.3971 - accuracy: 0.7896 - val_loss: 0.5658 - val_accuracy: 0.7186\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.3967 - accuracy: 0.8007 - val_loss: 0.5708 - val_accuracy: 0.7273\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.3957 - accuracy: 0.7989 - val_loss: 0.5657 - val_accuracy: 0.7186\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.3983 - accuracy: 0.7989 - val_loss: 0.5696 - val_accuracy: 0.7229\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.3928 - accuracy: 0.7933 - val_loss: 0.5713 - val_accuracy: 0.7403\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.3964 - accuracy: 0.7933 - val_loss: 0.5943 - val_accuracy: 0.7273\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.3996 - accuracy: 0.7914 - val_loss: 0.5676 - val_accuracy: 0.7273\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.3940 - accuracy: 0.7914 - val_loss: 0.5862 - val_accuracy: 0.7273\n",
      "Epoch 121/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.3922 - accuracy: 0.7970 - val_loss: 0.5795 - val_accuracy: 0.7273\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.3938 - accuracy: 0.8045 - val_loss: 0.5815 - val_accuracy: 0.7186\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.4098 - accuracy: 0.7803 - val_loss: 0.5855 - val_accuracy: 0.7273\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.3925 - accuracy: 0.7914 - val_loss: 0.5747 - val_accuracy: 0.7273\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.3925 - accuracy: 0.7989 - val_loss: 0.5819 - val_accuracy: 0.7186\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.3923 - accuracy: 0.8045 - val_loss: 0.5789 - val_accuracy: 0.7143\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.3905 - accuracy: 0.7952 - val_loss: 0.5788 - val_accuracy: 0.7229\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.3891 - accuracy: 0.7989 - val_loss: 0.5829 - val_accuracy: 0.7143\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 107us/step - loss: 0.3985 - accuracy: 0.7970 - val_loss: 0.5868 - val_accuracy: 0.7316\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.3912 - accuracy: 0.8045 - val_loss: 0.5964 - val_accuracy: 0.7229\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.3993 - accuracy: 0.7952 - val_loss: 0.5926 - val_accuracy: 0.7229\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.3989 - accuracy: 0.7989 - val_loss: 0.5712 - val_accuracy: 0.7100\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.3967 - accuracy: 0.7952 - val_loss: 0.5806 - val_accuracy: 0.6970\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.3956 - accuracy: 0.7952 - val_loss: 0.5890 - val_accuracy: 0.7100\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.3913 - accuracy: 0.8063 - val_loss: 0.5754 - val_accuracy: 0.7229\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.3888 - accuracy: 0.7952 - val_loss: 0.5800 - val_accuracy: 0.7143\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.3871 - accuracy: 0.8082 - val_loss: 0.5867 - val_accuracy: 0.7229\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.3913 - accuracy: 0.8026 - val_loss: 0.5896 - val_accuracy: 0.7316\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.3964 - accuracy: 0.7952 - val_loss: 0.5780 - val_accuracy: 0.7100\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.3874 - accuracy: 0.8082 - val_loss: 0.5991 - val_accuracy: 0.7359\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.3883 - accuracy: 0.8026 - val_loss: 0.5841 - val_accuracy: 0.7229\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.3854 - accuracy: 0.8101 - val_loss: 0.5781 - val_accuracy: 0.7273\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.3955 - accuracy: 0.8007 - val_loss: 0.5936 - val_accuracy: 0.7143\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.4037 - accuracy: 0.7970 - val_loss: 0.5803 - val_accuracy: 0.7143\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.3958 - accuracy: 0.7933 - val_loss: 0.6163 - val_accuracy: 0.7316\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.3965 - accuracy: 0.7914 - val_loss: 0.5754 - val_accuracy: 0.7143\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.3916 - accuracy: 0.8007 - val_loss: 0.5853 - val_accuracy: 0.7316\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.3835 - accuracy: 0.8007 - val_loss: 0.5828 - val_accuracy: 0.7229\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.4071 - accuracy: 0.7877 - val_loss: 0.5998 - val_accuracy: 0.7446\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.3914 - accuracy: 0.8119 - val_loss: 0.5891 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238fd205a48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### Another combination ###\n",
    "model = Sequential()\n",
    "model.add(Dense(12,  input_dim=8, init= 'uniform', activation = \"relu\"))\n",
    "#model.add(Dense(8,  init= 'uniform', activation = \"relu\"))\n",
    "model.add(Dense(1,   init= 'uniform', activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.6108 - val_loss: 0.6567 - val_accuracy: 0.6537\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 284us/step - loss: 0.6606 - accuracy: 0.6480 - val_loss: 0.6474 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 312us/step - loss: 0.6517 - accuracy: 0.6555 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.6435 - accuracy: 0.6443 - val_loss: 0.6309 - val_accuracy: 0.6580\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 294us/step - loss: 0.6399 - accuracy: 0.6387 - val_loss: 0.6290 - val_accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.6311 - accuracy: 0.6704 - val_loss: 0.6282 - val_accuracy: 0.6623\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.6308 - accuracy: 0.6536 - val_loss: 0.6190 - val_accuracy: 0.6753\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.6213 - accuracy: 0.6741 - val_loss: 0.6138 - val_accuracy: 0.6797\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 303us/step - loss: 0.6234 - accuracy: 0.6965 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.6186 - accuracy: 0.6741 - val_loss: 0.6150 - val_accuracy: 0.6970\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 284us/step - loss: 0.6127 - accuracy: 0.6890 - val_loss: 0.6026 - val_accuracy: 0.6883\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.6121 - accuracy: 0.6816 - val_loss: 0.6085 - val_accuracy: 0.6623\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.6063 - accuracy: 0.6741 - val_loss: 0.6074 - val_accuracy: 0.7056\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.6060 - accuracy: 0.6872 - val_loss: 0.6051 - val_accuracy: 0.6753\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.6058 - accuracy: 0.6946 - val_loss: 0.6189 - val_accuracy: 0.7100\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 276us/step - loss: 0.6012 - accuracy: 0.6927 - val_loss: 0.5981 - val_accuracy: 0.7100\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.6031 - accuracy: 0.6983 - val_loss: 0.6057 - val_accuracy: 0.7056\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 253us/step - loss: 0.5960 - accuracy: 0.7002 - val_loss: 0.5978 - val_accuracy: 0.6970\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.5975 - accuracy: 0.6834 - val_loss: 0.5987 - val_accuracy: 0.7056\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 297us/step - loss: 0.5950 - accuracy: 0.7020 - val_loss: 0.5885 - val_accuracy: 0.6926\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s 292us/step - loss: 0.5951 - accuracy: 0.6872 - val_loss: 0.5894 - val_accuracy: 0.7143\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5890 - accuracy: 0.6909 - val_loss: 0.5884 - val_accuracy: 0.6797\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.5928 - accuracy: 0.6853 - val_loss: 0.5847 - val_accuracy: 0.7100\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.5828 - accuracy: 0.6983 - val_loss: 0.5989 - val_accuracy: 0.6970\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - 0s 269us/step - loss: 0.5884 - accuracy: 0.6965 - val_loss: 0.6012 - val_accuracy: 0.7056\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5892 - accuracy: 0.6872 - val_loss: 0.5817 - val_accuracy: 0.7143\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 284us/step - loss: 0.5856 - accuracy: 0.6927 - val_loss: 0.5983 - val_accuracy: 0.7013\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.5975 - accuracy: 0.6946 - val_loss: 0.5923 - val_accuracy: 0.7186\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5853 - accuracy: 0.6909 - val_loss: 0.5910 - val_accuracy: 0.7013\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.5795 - accuracy: 0.6927 - val_loss: 0.5815 - val_accuracy: 0.7100\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.5811 - accuracy: 0.6983 - val_loss: 0.5841 - val_accuracy: 0.7186\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 240us/step - loss: 0.5759 - accuracy: 0.6909 - val_loss: 0.5884 - val_accuracy: 0.7056\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.5763 - accuracy: 0.6927 - val_loss: 0.5775 - val_accuracy: 0.7229\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5737 - accuracy: 0.6983 - val_loss: 0.5820 - val_accuracy: 0.6970\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5770 - accuracy: 0.6946 - val_loss: 0.5764 - val_accuracy: 0.7100\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5693 - accuracy: 0.7076 - val_loss: 0.5770 - val_accuracy: 0.7186\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.5713 - accuracy: 0.7039 - val_loss: 0.5921 - val_accuracy: 0.7056\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 280us/step - loss: 0.5695 - accuracy: 0.6946 - val_loss: 0.5747 - val_accuracy: 0.7143\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 210us/step - loss: 0.5677 - accuracy: 0.7169 - val_loss: 0.5769 - val_accuracy: 0.7100\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 284us/step - loss: 0.5655 - accuracy: 0.7076 - val_loss: 0.5741 - val_accuracy: 0.7186\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 303us/step - loss: 0.5663 - accuracy: 0.7207 - val_loss: 0.5758 - val_accuracy: 0.7056\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5610 - accuracy: 0.7151 - val_loss: 0.5723 - val_accuracy: 0.7403\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.5606 - accuracy: 0.7207 - val_loss: 0.5771 - val_accuracy: 0.7229\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 308us/step - loss: 0.5591 - accuracy: 0.7076 - val_loss: 0.5733 - val_accuracy: 0.7273\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 267us/step - loss: 0.5644 - accuracy: 0.7132 - val_loss: 0.5711 - val_accuracy: 0.7316\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.5563 - accuracy: 0.7225 - val_loss: 0.5747 - val_accuracy: 0.7273\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.5547 - accuracy: 0.7374 - val_loss: 0.5760 - val_accuracy: 0.7403\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 276us/step - loss: 0.5498 - accuracy: 0.7356 - val_loss: 0.5693 - val_accuracy: 0.7316\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.5516 - accuracy: 0.7151 - val_loss: 0.5708 - val_accuracy: 0.7273\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.5501 - accuracy: 0.7374 - val_loss: 0.5697 - val_accuracy: 0.7446\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.5485 - accuracy: 0.7393 - val_loss: 0.5710 - val_accuracy: 0.7403\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.5457 - accuracy: 0.7337 - val_loss: 0.5699 - val_accuracy: 0.7359\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.5416 - accuracy: 0.7318 - val_loss: 0.5690 - val_accuracy: 0.7273\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5501 - accuracy: 0.7337 - val_loss: 0.5787 - val_accuracy: 0.7316\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.5404 - accuracy: 0.7393 - val_loss: 0.5746 - val_accuracy: 0.7359\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 271us/step - loss: 0.5439 - accuracy: 0.7263 - val_loss: 0.5687 - val_accuracy: 0.7229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s 270us/step - loss: 0.5389 - accuracy: 0.7449 - val_loss: 0.5698 - val_accuracy: 0.7359\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 281us/step - loss: 0.5441 - accuracy: 0.7356 - val_loss: 0.5726 - val_accuracy: 0.7316\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.5340 - accuracy: 0.7393 - val_loss: 0.5815 - val_accuracy: 0.7229\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 297us/step - loss: 0.5297 - accuracy: 0.7579 - val_loss: 0.5805 - val_accuracy: 0.7316\n",
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s 281us/step - loss: 0.5327 - accuracy: 0.7430 - val_loss: 0.5735 - val_accuracy: 0.7229\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.5362 - accuracy: 0.7505 - val_loss: 0.5669 - val_accuracy: 0.7229\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5267 - accuracy: 0.7449 - val_loss: 0.5725 - val_accuracy: 0.7273\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.5283 - accuracy: 0.7523 - val_loss: 0.5764 - val_accuracy: 0.7143\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 307us/step - loss: 0.5227 - accuracy: 0.7374 - val_loss: 0.5733 - val_accuracy: 0.7316\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.5277 - accuracy: 0.7337 - val_loss: 0.5672 - val_accuracy: 0.7229\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5294 - accuracy: 0.7356 - val_loss: 0.5741 - val_accuracy: 0.7273\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.5247 - accuracy: 0.7561 - val_loss: 0.5748 - val_accuracy: 0.7229\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5214 - accuracy: 0.7374 - val_loss: 0.5748 - val_accuracy: 0.7143\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.5241 - accuracy: 0.7430 - val_loss: 0.5788 - val_accuracy: 0.7359\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.5210 - accuracy: 0.7263 - val_loss: 0.5720 - val_accuracy: 0.7229\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5276 - accuracy: 0.7318 - val_loss: 0.5704 - val_accuracy: 0.7229\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 280us/step - loss: 0.5210 - accuracy: 0.7430 - val_loss: 0.5680 - val_accuracy: 0.7229\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.5137 - accuracy: 0.7561 - val_loss: 0.5711 - val_accuracy: 0.7273\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 276us/step - loss: 0.5134 - accuracy: 0.7486 - val_loss: 0.5772 - val_accuracy: 0.7359\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 281us/step - loss: 0.5155 - accuracy: 0.7523 - val_loss: 0.5837 - val_accuracy: 0.7359\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.5119 - accuracy: 0.7598 - val_loss: 0.5797 - val_accuracy: 0.7316\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.5178 - accuracy: 0.7505 - val_loss: 0.5737 - val_accuracy: 0.7403\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5110 - accuracy: 0.7505 - val_loss: 0.5771 - val_accuracy: 0.7489\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.5138 - accuracy: 0.7561 - val_loss: 0.5742 - val_accuracy: 0.7143\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.5140 - accuracy: 0.7374 - val_loss: 0.5799 - val_accuracy: 0.7143\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.5185 - accuracy: 0.7467 - val_loss: 0.5724 - val_accuracy: 0.7403\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 298us/step - loss: 0.5134 - accuracy: 0.7523 - val_loss: 0.5741 - val_accuracy: 0.7359\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 294us/step - loss: 0.5061 - accuracy: 0.7486 - val_loss: 0.5736 - val_accuracy: 0.7273\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.5092 - accuracy: 0.7635 - val_loss: 0.5792 - val_accuracy: 0.7186\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 275us/step - loss: 0.5236 - accuracy: 0.7449 - val_loss: 0.5802 - val_accuracy: 0.7143\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 257us/step - loss: 0.5065 - accuracy: 0.7598 - val_loss: 0.5772 - val_accuracy: 0.7273\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 280us/step - loss: 0.5080 - accuracy: 0.7505 - val_loss: 0.5696 - val_accuracy: 0.7316\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.5198 - accuracy: 0.7467 - val_loss: 0.5856 - val_accuracy: 0.7403\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.5132 - accuracy: 0.7393 - val_loss: 0.5740 - val_accuracy: 0.7316\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.5099 - accuracy: 0.7523 - val_loss: 0.5672 - val_accuracy: 0.7273\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 281us/step - loss: 0.5066 - accuracy: 0.7672 - val_loss: 0.5739 - val_accuracy: 0.7316\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 266us/step - loss: 0.5012 - accuracy: 0.7616 - val_loss: 0.5829 - val_accuracy: 0.7273\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.5111 - accuracy: 0.7449 - val_loss: 0.5786 - val_accuracy: 0.7056\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 298us/step - loss: 0.5105 - accuracy: 0.7505 - val_loss: 0.5763 - val_accuracy: 0.7359\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s 293us/step - loss: 0.4994 - accuracy: 0.7486 - val_loss: 0.5748 - val_accuracy: 0.7359\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.5719 - val_accuracy: 0.7359\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.5048 - accuracy: 0.7467 - val_loss: 0.5718 - val_accuracy: 0.7359\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.5059 - accuracy: 0.7561 - val_loss: 0.5840 - val_accuracy: 0.7229\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.6047 - val_accuracy: 0.7013\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.5121 - accuracy: 0.7523 - val_loss: 0.5714 - val_accuracy: 0.7273\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.5006 - accuracy: 0.7654 - val_loss: 0.5811 - val_accuracy: 0.7403\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.5024 - accuracy: 0.7449 - val_loss: 0.5753 - val_accuracy: 0.7273\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4964 - accuracy: 0.7523 - val_loss: 0.5759 - val_accuracy: 0.7446\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.4965 - accuracy: 0.7654 - val_loss: 0.5732 - val_accuracy: 0.7316\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 277us/step - loss: 0.4960 - accuracy: 0.7616 - val_loss: 0.5868 - val_accuracy: 0.7403\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.5002 - accuracy: 0.7598 - val_loss: 0.5766 - val_accuracy: 0.7403\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 285us/step - loss: 0.4975 - accuracy: 0.7747 - val_loss: 0.5774 - val_accuracy: 0.7056\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.4985 - accuracy: 0.7542 - val_loss: 0.5772 - val_accuracy: 0.7359\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 279us/step - loss: 0.4988 - accuracy: 0.7542 - val_loss: 0.5755 - val_accuracy: 0.7403\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4937 - accuracy: 0.7542 - val_loss: 0.5758 - val_accuracy: 0.7359\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.4978 - accuracy: 0.7579 - val_loss: 0.5776 - val_accuracy: 0.7316\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 292us/step - loss: 0.4932 - accuracy: 0.7635 - val_loss: 0.5842 - val_accuracy: 0.7316\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.4932 - accuracy: 0.7579 - val_loss: 0.5807 - val_accuracy: 0.7316\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4933 - accuracy: 0.7616 - val_loss: 0.5774 - val_accuracy: 0.7143\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.4931 - accuracy: 0.7709 - val_loss: 0.5738 - val_accuracy: 0.7229\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.4898 - accuracy: 0.7635 - val_loss: 0.5787 - val_accuracy: 0.7446\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.4931 - accuracy: 0.7616 - val_loss: 0.5765 - val_accuracy: 0.7359\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 294us/step - loss: 0.4942 - accuracy: 0.7579 - val_loss: 0.5883 - val_accuracy: 0.7403\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.4923 - accuracy: 0.7561 - val_loss: 0.5761 - val_accuracy: 0.7273\n",
      "Epoch 121/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.4939 - accuracy: 0.7616 - val_loss: 0.5793 - val_accuracy: 0.7489\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 301us/step - loss: 0.4858 - accuracy: 0.7654 - val_loss: 0.5910 - val_accuracy: 0.7143\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 302us/step - loss: 0.4927 - accuracy: 0.7598 - val_loss: 0.5963 - val_accuracy: 0.7316\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 294us/step - loss: 0.4892 - accuracy: 0.7598 - val_loss: 0.5821 - val_accuracy: 0.7316\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s 290us/step - loss: 0.4904 - accuracy: 0.7635 - val_loss: 0.5895 - val_accuracy: 0.7359\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 288us/step - loss: 0.4929 - accuracy: 0.7691 - val_loss: 0.5810 - val_accuracy: 0.7186\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.4929 - accuracy: 0.7728 - val_loss: 0.5862 - val_accuracy: 0.7316\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 276us/step - loss: 0.4927 - accuracy: 0.7709 - val_loss: 0.5784 - val_accuracy: 0.7316\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 282us/step - loss: 0.4874 - accuracy: 0.7747 - val_loss: 0.5795 - val_accuracy: 0.7489\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 283us/step - loss: 0.4841 - accuracy: 0.7821 - val_loss: 0.5844 - val_accuracy: 0.7403\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 297us/step - loss: 0.4902 - accuracy: 0.7747 - val_loss: 0.5784 - val_accuracy: 0.7403\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.4881 - accuracy: 0.7803 - val_loss: 0.5940 - val_accuracy: 0.7316\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4906 - accuracy: 0.7765 - val_loss: 0.5858 - val_accuracy: 0.7359\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 274us/step - loss: 0.4844 - accuracy: 0.7579 - val_loss: 0.5745 - val_accuracy: 0.7359\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 287us/step - loss: 0.4841 - accuracy: 0.7561 - val_loss: 0.5844 - val_accuracy: 0.7316\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4973 - accuracy: 0.7616 - val_loss: 0.5758 - val_accuracy: 0.7359\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 295us/step - loss: 0.4804 - accuracy: 0.7709 - val_loss: 0.5897 - val_accuracy: 0.7489\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 298us/step - loss: 0.4865 - accuracy: 0.7728 - val_loss: 0.5733 - val_accuracy: 0.7403\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 236us/step - loss: 0.4905 - accuracy: 0.7654 - val_loss: 0.5756 - val_accuracy: 0.7229\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 249us/step - loss: 0.5030 - accuracy: 0.7579 - val_loss: 0.5758 - val_accuracy: 0.7403\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4868 - accuracy: 0.7709 - val_loss: 0.5800 - val_accuracy: 0.7229\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 276us/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5961 - val_accuracy: 0.7273\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 292us/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5833 - val_accuracy: 0.7532\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 289us/step - loss: 0.4862 - accuracy: 0.7691 - val_loss: 0.5905 - val_accuracy: 0.7359\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 294us/step - loss: 0.4865 - accuracy: 0.7654 - val_loss: 0.5772 - val_accuracy: 0.7359\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 299us/step - loss: 0.4883 - accuracy: 0.7579 - val_loss: 0.5765 - val_accuracy: 0.7446\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 278us/step - loss: 0.4813 - accuracy: 0.7672 - val_loss: 0.5831 - val_accuracy: 0.7532\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 240us/step - loss: 0.4945 - accuracy: 0.7672 - val_loss: 0.5878 - val_accuracy: 0.7532\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 281us/step - loss: 0.4881 - accuracy: 0.7691 - val_loss: 0.5851 - val_accuracy: 0.7403\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 286us/step - loss: 0.4908 - accuracy: 0.7635 - val_loss: 0.5744 - val_accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238fd40ce88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=150,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
