{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Contents\\\\Kaggle\\\\Ionosphere.data\", header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:307: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:313: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values\n",
    "X = df[:, 0:34]\n",
    "Y = df[:, 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0.99539, -0.05889, 0.8524299999999999, 0.02306,\n",
       "         0.8339799999999999, -0.37708, 1.0, 0.0376, 0.8524299999999999,\n",
       "         -0.17755, 0.59755, -0.44945, 0.60536, -0.38223,\n",
       "         0.8435600000000001, -0.38542, 0.58212, -0.32192, 0.56971,\n",
       "         -0.29674, 0.36946, -0.47357, 0.56811, -0.51171,\n",
       "         0.41078000000000003, -0.46168000000000003, 0.21266, -0.3409,\n",
       "         0.42267, -0.54487, 0.18641, -0.453],\n",
       "        [1, 0, 1.0, -0.18829, 0.93035, -0.36156, -0.10868,\n",
       "         -0.9359700000000001, 1.0, -0.045489999999999996, 0.50874,\n",
       "         -0.67743, 0.34431999999999996, -0.69707, -0.51685, -0.97515,\n",
       "         0.05499, -0.62237, 0.33109, -1.0, -0.13151, -0.453, -0.18056,\n",
       "         -0.35734, -0.20332, -0.26569, -0.20468, -0.18400999999999998,\n",
       "         -0.1904, -0.11592999999999999, -0.16626, -0.06287999999999999,\n",
       "         -0.13738, -0.02447],\n",
       "        [1, 0, 1.0, -0.03365, 1.0, 0.00485, 1.0, -0.12062, 0.88965,\n",
       "         0.01198, 0.73082, 0.05346, 0.8544299999999999, 0.00827, 0.54591,\n",
       "         0.00299, 0.83775, -0.13644, 0.75535, -0.0854, 0.70887, -0.27502,\n",
       "         0.43385, -0.12062, 0.57528, -0.4022, 0.5898399999999999,\n",
       "         -0.22145, 0.431, -0.17365, 0.60436, -0.2418, 0.56045, -0.38238],\n",
       "        [1, 0, 1.0, -0.45161, 1.0, 1.0, 0.71216, -1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.0, -1.0, 0.14515999999999998, 0.54094, -0.3933, -1.0,\n",
       "         -0.54467, -0.69975, 1.0, 0.0, 0.0, 1.0, 0.90695, 0.51613, 1.0,\n",
       "         1.0, -0.20099, 0.25682, 1.0, -0.32382, 1.0],\n",
       "        [1, 0, 1.0, -0.02401, 0.9414, 0.06531, 0.92106, -0.23255, 0.77152,\n",
       "         -0.16399, 0.52798, -0.20275, 0.56409, -0.0071200000000000005,\n",
       "         0.34395, -0.27457, 0.5294, -0.2178, 0.45106999999999997,\n",
       "         -0.17812999999999998, 0.059820000000000005, -0.35575, 0.02309,\n",
       "         -0.52879, 0.03286, -0.65158, 0.1329, -0.5320600000000001,\n",
       "         0.02431, -0.62197, -0.05707, -0.59573, -0.04608,\n",
       "         -0.6569699999999999]], dtype=object),\n",
       " array(['g', 'b', 'g', 'b', 'g'], dtype=object))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5],Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 34)                1190      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 35        \n",
      "=================================================================\n",
      "Total params: 1,225\n",
      "Trainable params: 1,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(34, input_dim=34, kernel_initializer='normal', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/150\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.6784 - accuracy: 0.6426 - val_loss: 0.6703 - val_accuracy: 0.6638\n",
      "Epoch 2/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.6232 - accuracy: 0.7745 - val_loss: 0.6372 - val_accuracy: 0.6638\n",
      "Epoch 3/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.5670 - accuracy: 0.8000 - val_loss: 0.5849 - val_accuracy: 0.7759\n",
      "Epoch 4/150\n",
      "235/235 [==============================] - 0s 330us/step - loss: 0.5035 - accuracy: 0.8128 - val_loss: 0.5247 - val_accuracy: 0.8793\n",
      "Epoch 5/150\n",
      "235/235 [==============================] - 0s 254us/step - loss: 0.4499 - accuracy: 0.8255 - val_loss: 0.4751 - val_accuracy: 0.9052\n",
      "Epoch 6/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.4045 - accuracy: 0.8426 - val_loss: 0.4304 - val_accuracy: 0.8966\n",
      "Epoch 7/150\n",
      "235/235 [==============================] - 0s 303us/step - loss: 0.3693 - accuracy: 0.8553 - val_loss: 0.3903 - val_accuracy: 0.8966\n",
      "Epoch 8/150\n",
      "235/235 [==============================] - 0s 266us/step - loss: 0.3398 - accuracy: 0.8766 - val_loss: 0.3554 - val_accuracy: 0.8966\n",
      "Epoch 9/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.3140 - accuracy: 0.8766 - val_loss: 0.3316 - val_accuracy: 0.8966\n",
      "Epoch 10/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.2944 - accuracy: 0.8766 - val_loss: 0.3232 - val_accuracy: 0.8966\n",
      "Epoch 11/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.2769 - accuracy: 0.8809 - val_loss: 0.2982 - val_accuracy: 0.9052\n",
      "Epoch 12/150\n",
      "235/235 [==============================] - 0s 278us/step - loss: 0.2634 - accuracy: 0.8894 - val_loss: 0.2841 - val_accuracy: 0.9052\n",
      "Epoch 13/150\n",
      "235/235 [==============================] - 0s 315us/step - loss: 0.2473 - accuracy: 0.8894 - val_loss: 0.2662 - val_accuracy: 0.9052\n",
      "Epoch 14/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.2375 - accuracy: 0.9021 - val_loss: 0.2586 - val_accuracy: 0.9310\n",
      "Epoch 15/150\n",
      "235/235 [==============================] - 0s 340us/step - loss: 0.2267 - accuracy: 0.9064 - val_loss: 0.2588 - val_accuracy: 0.9224\n",
      "Epoch 16/150\n",
      "235/235 [==============================] - 0s 284us/step - loss: 0.2190 - accuracy: 0.9021 - val_loss: 0.2322 - val_accuracy: 0.9224\n",
      "Epoch 17/150\n",
      "235/235 [==============================] - 0s 355us/step - loss: 0.2094 - accuracy: 0.9021 - val_loss: 0.2290 - val_accuracy: 0.9224\n",
      "Epoch 18/150\n",
      "235/235 [==============================] - 0s 218us/step - loss: 0.2004 - accuracy: 0.9106 - val_loss: 0.2249 - val_accuracy: 0.9224\n",
      "Epoch 19/150\n",
      "235/235 [==============================] - 0s 248us/step - loss: 0.1929 - accuracy: 0.9149 - val_loss: 0.2172 - val_accuracy: 0.9224\n",
      "Epoch 20/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.1865 - accuracy: 0.9149 - val_loss: 0.2107 - val_accuracy: 0.9224\n",
      "Epoch 21/150\n",
      "235/235 [==============================] - 0s 308us/step - loss: 0.1798 - accuracy: 0.9149 - val_loss: 0.2007 - val_accuracy: 0.9310\n",
      "Epoch 22/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.1748 - accuracy: 0.9191 - val_loss: 0.1991 - val_accuracy: 0.9310\n",
      "Epoch 23/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.1718 - accuracy: 0.9277 - val_loss: 0.1890 - val_accuracy: 0.9310\n",
      "Epoch 24/150\n",
      "235/235 [==============================] - 0s 301us/step - loss: 0.1632 - accuracy: 0.9362 - val_loss: 0.1777 - val_accuracy: 0.9397\n",
      "Epoch 25/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.1588 - accuracy: 0.9362 - val_loss: 0.1759 - val_accuracy: 0.9397\n",
      "Epoch 26/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.1525 - accuracy: 0.9404 - val_loss: 0.1712 - val_accuracy: 0.9483\n",
      "Epoch 27/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.1491 - accuracy: 0.9404 - val_loss: 0.1669 - val_accuracy: 0.9483\n",
      "Epoch 28/150\n",
      "235/235 [==============================] - 0s 270us/step - loss: 0.1435 - accuracy: 0.9447 - val_loss: 0.1657 - val_accuracy: 0.9483\n",
      "Epoch 29/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.1396 - accuracy: 0.9489 - val_loss: 0.1627 - val_accuracy: 0.9483\n",
      "Epoch 30/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.1354 - accuracy: 0.9489 - val_loss: 0.1566 - val_accuracy: 0.9483\n",
      "Epoch 31/150\n",
      "235/235 [==============================] - 0s 284us/step - loss: 0.1316 - accuracy: 0.9532 - val_loss: 0.1489 - val_accuracy: 0.9483\n",
      "Epoch 32/150\n",
      "235/235 [==============================] - 0s 266us/step - loss: 0.1282 - accuracy: 0.9532 - val_loss: 0.1435 - val_accuracy: 0.9483\n",
      "Epoch 33/150\n",
      "235/235 [==============================] - 0s 324us/step - loss: 0.1246 - accuracy: 0.9574 - val_loss: 0.1444 - val_accuracy: 0.9483\n",
      "Epoch 34/150\n",
      "235/235 [==============================] - 0s 337us/step - loss: 0.1219 - accuracy: 0.9574 - val_loss: 0.1404 - val_accuracy: 0.9569\n",
      "Epoch 35/150\n",
      "235/235 [==============================] - 0s 298us/step - loss: 0.1184 - accuracy: 0.9617 - val_loss: 0.1362 - val_accuracy: 0.9569\n",
      "Epoch 36/150\n",
      "235/235 [==============================] - 0s 275us/step - loss: 0.1147 - accuracy: 0.9617 - val_loss: 0.1359 - val_accuracy: 0.9569\n",
      "Epoch 37/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.1121 - accuracy: 0.9617 - val_loss: 0.1318 - val_accuracy: 0.9655\n",
      "Epoch 38/150\n",
      "235/235 [==============================] - 0s 286us/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 0.1261 - val_accuracy: 0.9655\n",
      "Epoch 39/150\n",
      "235/235 [==============================] - 0s 304us/step - loss: 0.1075 - accuracy: 0.9617 - val_loss: 0.1255 - val_accuracy: 0.9655\n",
      "Epoch 40/150\n",
      "235/235 [==============================] - 0s 342us/step - loss: 0.1046 - accuracy: 0.9617 - val_loss: 0.1221 - val_accuracy: 0.9741\n",
      "Epoch 41/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.1016 - accuracy: 0.9617 - val_loss: 0.1230 - val_accuracy: 0.9741\n",
      "Epoch 42/150\n",
      "235/235 [==============================] - 0s 282us/step - loss: 0.0992 - accuracy: 0.9660 - val_loss: 0.1173 - val_accuracy: 0.9741\n",
      "Epoch 43/150\n",
      "235/235 [==============================] - 0s 299us/step - loss: 0.0979 - accuracy: 0.9617 - val_loss: 0.1121 - val_accuracy: 0.9741\n",
      "Epoch 44/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.0950 - accuracy: 0.9660 - val_loss: 0.1165 - val_accuracy: 0.9741\n",
      "Epoch 45/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.0927 - accuracy: 0.9660 - val_loss: 0.1108 - val_accuracy: 0.9741\n",
      "Epoch 46/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.0904 - accuracy: 0.9702 - val_loss: 0.1122 - val_accuracy: 0.9828\n",
      "Epoch 47/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.0887 - accuracy: 0.9660 - val_loss: 0.1103 - val_accuracy: 0.9828\n",
      "Epoch 48/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0860 - accuracy: 0.9702 - val_loss: 0.1065 - val_accuracy: 0.9828\n",
      "Epoch 49/150\n",
      "235/235 [==============================] - 0s 280us/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 0.1020 - val_accuracy: 0.9828\n",
      "Epoch 50/150\n",
      "235/235 [==============================] - 0s 312us/step - loss: 0.0829 - accuracy: 0.9702 - val_loss: 0.1049 - val_accuracy: 0.9914\n",
      "Epoch 51/150\n",
      "235/235 [==============================] - 0s 276us/step - loss: 0.0807 - accuracy: 0.9702 - val_loss: 0.1021 - val_accuracy: 0.9828\n",
      "Epoch 52/150\n",
      "235/235 [==============================] - 0s 338us/step - loss: 0.0789 - accuracy: 0.9702 - val_loss: 0.1048 - val_accuracy: 0.9828\n",
      "Epoch 53/150\n",
      "235/235 [==============================] - 0s 284us/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 0.0971 - val_accuracy: 0.9914\n",
      "Epoch 54/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.0755 - accuracy: 0.9702 - val_loss: 0.0955 - val_accuracy: 0.9914\n",
      "Epoch 55/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.0740 - accuracy: 0.9702 - val_loss: 0.0942 - val_accuracy: 0.9914\n",
      "Epoch 56/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.0725 - accuracy: 0.9702 - val_loss: 0.0909 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "235/235 [==============================] - 0s 296us/step - loss: 0.0713 - accuracy: 0.9702 - val_loss: 0.0931 - val_accuracy: 0.9914\n",
      "Epoch 58/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.0694 - accuracy: 0.9745 - val_loss: 0.0920 - val_accuracy: 0.9914\n",
      "Epoch 59/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.0680 - accuracy: 0.9787 - val_loss: 0.0895 - val_accuracy: 0.9914\n",
      "Epoch 60/150\n",
      "235/235 [==============================] - 0s 305us/step - loss: 0.0666 - accuracy: 0.9745 - val_loss: 0.0890 - val_accuracy: 0.9914\n",
      "Epoch 61/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.0656 - accuracy: 0.9830 - val_loss: 0.0888 - val_accuracy: 0.9914\n",
      "Epoch 62/150\n",
      "235/235 [==============================] - 0s 282us/step - loss: 0.0652 - accuracy: 0.9830 - val_loss: 0.0853 - val_accuracy: 0.9914\n",
      "Epoch 63/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.0621 - accuracy: 0.9872 - val_loss: 0.0866 - val_accuracy: 0.9914\n",
      "Epoch 64/150\n",
      "235/235 [==============================] - 0s 324us/step - loss: 0.0617 - accuracy: 0.9830 - val_loss: 0.0871 - val_accuracy: 0.9914\n",
      "Epoch 65/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0597 - accuracy: 0.9872 - val_loss: 0.0842 - val_accuracy: 0.9914\n",
      "Epoch 66/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.0585 - accuracy: 0.9872 - val_loss: 0.0821 - val_accuracy: 0.9914\n",
      "Epoch 67/150\n",
      "235/235 [==============================] - 0s 325us/step - loss: 0.0577 - accuracy: 0.9872 - val_loss: 0.0815 - val_accuracy: 0.9914\n",
      "Epoch 68/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.0572 - accuracy: 0.9872 - val_loss: 0.0822 - val_accuracy: 0.9914\n",
      "Epoch 69/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0548 - accuracy: 0.9872 - val_loss: 0.0811 - val_accuracy: 0.9914\n",
      "Epoch 70/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0537 - accuracy: 0.9872 - val_loss: 0.0793 - val_accuracy: 0.9914\n",
      "Epoch 71/150\n",
      "235/235 [==============================] - 0s 339us/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.0781 - val_accuracy: 0.9914\n",
      "Epoch 72/150\n",
      "235/235 [==============================] - 0s 289us/step - loss: 0.0521 - accuracy: 0.9872 - val_loss: 0.0776 - val_accuracy: 0.9914\n",
      "Epoch 73/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.0508 - accuracy: 0.9872 - val_loss: 0.0771 - val_accuracy: 0.9914\n",
      "Epoch 74/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.0494 - accuracy: 0.9872 - val_loss: 0.0780 - val_accuracy: 0.9914\n",
      "Epoch 75/150\n",
      "235/235 [==============================] - 0s 264us/step - loss: 0.0488 - accuracy: 0.9872 - val_loss: 0.0754 - val_accuracy: 0.9914\n",
      "Epoch 76/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.0479 - accuracy: 0.9915 - val_loss: 0.0766 - val_accuracy: 0.9914\n",
      "Epoch 77/150\n",
      "235/235 [==============================] - 0s 316us/step - loss: 0.0468 - accuracy: 0.9915 - val_loss: 0.0745 - val_accuracy: 0.9914\n",
      "Epoch 78/150\n",
      "235/235 [==============================] - 0s 314us/step - loss: 0.0466 - accuracy: 0.9915 - val_loss: 0.0739 - val_accuracy: 0.9914\n",
      "Epoch 79/150\n",
      "235/235 [==============================] - 0s 305us/step - loss: 0.0449 - accuracy: 0.9915 - val_loss: 0.0717 - val_accuracy: 0.9914\n",
      "Epoch 80/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.0443 - accuracy: 0.9915 - val_loss: 0.0735 - val_accuracy: 0.9914\n",
      "Epoch 81/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0436 - accuracy: 0.9915 - val_loss: 0.0709 - val_accuracy: 0.9914\n",
      "Epoch 82/150\n",
      "235/235 [==============================] - 0s 337us/step - loss: 0.0428 - accuracy: 0.9915 - val_loss: 0.0725 - val_accuracy: 0.9914\n",
      "Epoch 83/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.0420 - accuracy: 0.9915 - val_loss: 0.0719 - val_accuracy: 0.9914\n",
      "Epoch 84/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 0.0693 - val_accuracy: 0.9914\n",
      "Epoch 85/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0409 - accuracy: 0.9915 - val_loss: 0.0714 - val_accuracy: 0.9914\n",
      "Epoch 86/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0401 - accuracy: 0.9915 - val_loss: 0.0697 - val_accuracy: 0.9914\n",
      "Epoch 87/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.0391 - accuracy: 0.9915 - val_loss: 0.0716 - val_accuracy: 0.9914\n",
      "Epoch 88/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.0384 - accuracy: 0.9915 - val_loss: 0.0697 - val_accuracy: 0.9914\n",
      "Epoch 89/150\n",
      "235/235 [==============================] - 0s 278us/step - loss: 0.0377 - accuracy: 0.9915 - val_loss: 0.0695 - val_accuracy: 0.9914\n",
      "Epoch 90/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.0369 - accuracy: 0.9915 - val_loss: 0.0693 - val_accuracy: 0.9914\n",
      "Epoch 91/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0363 - accuracy: 0.9915 - val_loss: 0.0695 - val_accuracy: 0.9914\n",
      "Epoch 92/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0359 - accuracy: 0.9915 - val_loss: 0.0694 - val_accuracy: 0.9914\n",
      "Epoch 93/150\n",
      "235/235 [==============================] - 0s 316us/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.0692 - val_accuracy: 0.9914\n",
      "Epoch 94/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0358 - accuracy: 0.9915 - val_loss: 0.0688 - val_accuracy: 0.9914\n",
      "Epoch 95/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 0.0687 - val_accuracy: 0.9914\n",
      "Epoch 96/150\n",
      "235/235 [==============================] - 0s 273us/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.0685 - val_accuracy: 0.9914\n",
      "Epoch 97/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0696 - val_accuracy: 0.9914\n",
      "Epoch 98/150\n",
      "235/235 [==============================] - 0s 309us/step - loss: 0.0321 - accuracy: 0.9915 - val_loss: 0.0691 - val_accuracy: 0.9914\n",
      "Epoch 99/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 0.0674 - val_accuracy: 0.9914\n",
      "Epoch 100/150\n",
      "235/235 [==============================] - 0s 310us/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.0671 - val_accuracy: 0.9914\n",
      "Epoch 101/150\n",
      "235/235 [==============================] - 0s 294us/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 0.0681 - val_accuracy: 0.9914\n",
      "Epoch 102/150\n",
      "235/235 [==============================] - 0s 298us/step - loss: 0.0297 - accuracy: 0.9957 - val_loss: 0.0687 - val_accuracy: 0.9914\n",
      "Epoch 103/150\n",
      "235/235 [==============================] - 0s 269us/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0680 - val_accuracy: 0.9914\n",
      "Epoch 104/150\n",
      "235/235 [==============================] - 0s 308us/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0676 - val_accuracy: 0.9914\n",
      "Epoch 105/150\n",
      "235/235 [==============================] - 0s 266us/step - loss: 0.0289 - accuracy: 0.9957 - val_loss: 0.0709 - val_accuracy: 0.9914\n",
      "Epoch 106/150\n",
      "235/235 [==============================] - 0s 306us/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0679 - val_accuracy: 0.9914\n",
      "Epoch 107/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0684 - val_accuracy: 0.9914\n",
      "Epoch 108/150\n",
      "235/235 [==============================] - 0s 289us/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.0688 - val_accuracy: 0.9914\n",
      "Epoch 109/150\n",
      "235/235 [==============================] - 0s 305us/step - loss: 0.0264 - accuracy: 0.9957 - val_loss: 0.0695 - val_accuracy: 0.9914\n",
      "Epoch 110/150\n",
      "235/235 [==============================] - 0s 314us/step - loss: 0.0264 - accuracy: 0.9957 - val_loss: 0.0660 - val_accuracy: 0.9914\n",
      "Epoch 111/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0687 - val_accuracy: 0.9914\n",
      "Epoch 112/150\n",
      "235/235 [==============================] - 0s 305us/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 0.0703 - val_accuracy: 0.9914\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 284us/step - loss: 0.0248 - accuracy: 0.9957 - val_loss: 0.0683 - val_accuracy: 0.9914\n",
      "Epoch 114/150\n",
      "235/235 [==============================] - 0s 277us/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0702 - val_accuracy: 0.9828\n",
      "Epoch 115/150\n",
      "235/235 [==============================] - 0s 304us/step - loss: 0.0238 - accuracy: 0.9957 - val_loss: 0.0693 - val_accuracy: 0.9914\n",
      "Epoch 116/150\n",
      "235/235 [==============================] - 0s 344us/step - loss: 0.0235 - accuracy: 0.9957 - val_loss: 0.0686 - val_accuracy: 0.9828\n",
      "Epoch 117/150\n",
      "235/235 [==============================] - 0s 265us/step - loss: 0.0231 - accuracy: 0.9957 - val_loss: 0.0686 - val_accuracy: 0.9828\n",
      "Epoch 118/150\n",
      "235/235 [==============================] - 0s 304us/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.0715 - val_accuracy: 0.9828\n",
      "Epoch 119/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.0683 - val_accuracy: 0.9828\n",
      "Epoch 120/150\n",
      "235/235 [==============================] - 0s 301us/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 0.0713 - val_accuracy: 0.9828\n",
      "Epoch 121/150\n",
      "235/235 [==============================] - 0s 284us/step - loss: 0.0223 - accuracy: 0.9957 - val_loss: 0.0677 - val_accuracy: 0.9828\n",
      "Epoch 122/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 0.0728 - val_accuracy: 0.9828\n",
      "Epoch 123/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.0707 - val_accuracy: 0.9828\n",
      "Epoch 124/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.0700 - val_accuracy: 0.9828\n",
      "Epoch 125/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0711 - val_accuracy: 0.9828\n",
      "Epoch 126/150\n",
      "235/235 [==============================] - 0s 290us/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.0702 - val_accuracy: 0.9828\n",
      "Epoch 127/150\n",
      "235/235 [==============================] - 0s 308us/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0697 - val_accuracy: 0.9828\n",
      "Epoch 128/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0716 - val_accuracy: 0.9828\n",
      "Epoch 129/150\n",
      "235/235 [==============================] - 0s 327us/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.0712 - val_accuracy: 0.9828\n",
      "Epoch 130/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.0711 - val_accuracy: 0.9828\n",
      "Epoch 131/150\n",
      "235/235 [==============================] - 0s 289us/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0701 - val_accuracy: 0.9828\n",
      "Epoch 132/150\n",
      "235/235 [==============================] - 0s 305us/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.0675 - val_accuracy: 0.9828\n",
      "Epoch 133/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.0776 - val_accuracy: 0.9828\n",
      "Epoch 134/150\n",
      "235/235 [==============================] - 0s 274us/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.0729 - val_accuracy: 0.9828\n",
      "Epoch 135/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.0701 - val_accuracy: 0.9828\n",
      "Epoch 136/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0721 - val_accuracy: 0.9828\n",
      "Epoch 137/150\n",
      "235/235 [==============================] - 0s 308us/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0758 - val_accuracy: 0.9828\n",
      "Epoch 138/150\n",
      "235/235 [==============================] - 0s 307us/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0728 - val_accuracy: 0.9828\n",
      "Epoch 139/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0746 - val_accuracy: 0.9828\n",
      "Epoch 140/150\n",
      "235/235 [==============================] - 0s 329us/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.0723 - val_accuracy: 0.9828\n",
      "Epoch 141/150\n",
      "235/235 [==============================] - 0s 286us/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.0762 - val_accuracy: 0.9828\n",
      "Epoch 142/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.0734 - val_accuracy: 0.9828\n",
      "Epoch 143/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0759 - val_accuracy: 0.9828\n",
      "Epoch 144/150\n",
      "235/235 [==============================] - 0s 342us/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0757 - val_accuracy: 0.9828\n",
      "Epoch 145/150\n",
      "235/235 [==============================] - 0s 265us/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0761 - val_accuracy: 0.9828\n",
      "Epoch 146/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0745 - val_accuracy: 0.9828\n",
      "Epoch 147/150\n",
      "235/235 [==============================] - 0s 294us/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0763 - val_accuracy: 0.9828\n",
      "Epoch 148/150\n",
      "235/235 [==============================] - 0s 279us/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0758 - val_accuracy: 0.9828\n",
      "Epoch 149/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0753 - val_accuracy: 0.9828\n",
      "Epoch 150/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0758 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2692eedcb88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 34)                1190      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 35        \n",
      "=================================================================\n",
      "Total params: 1,225\n",
      "Trainable params: 1,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(34,)))\n",
    "model.add(Dense(34,  kernel_initializer='normal', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/150\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.6213 - val_loss: 0.6919 - val_accuracy: 0.6034\n",
      "Epoch 2/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.6288 - accuracy: 0.7702 - val_loss: 0.6677 - val_accuracy: 0.6466\n",
      "Epoch 3/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.5739 - accuracy: 0.7957 - val_loss: 0.6223 - val_accuracy: 0.7328\n",
      "Epoch 4/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.5229 - accuracy: 0.8000 - val_loss: 0.5666 - val_accuracy: 0.8103\n",
      "Epoch 5/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.4714 - accuracy: 0.8170 - val_loss: 0.5012 - val_accuracy: 0.8707\n",
      "Epoch 6/150\n",
      "235/235 [==============================] - 0s 324us/step - loss: 0.4250 - accuracy: 0.8340 - val_loss: 0.4751 - val_accuracy: 0.8879\n",
      "Epoch 7/150\n",
      "235/235 [==============================] - 0s 272us/step - loss: 0.3960 - accuracy: 0.8426 - val_loss: 0.4265 - val_accuracy: 0.8966\n",
      "Epoch 8/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.3878 - accuracy: 0.8511 - val_loss: 0.3987 - val_accuracy: 0.8966\n",
      "Epoch 9/150\n",
      "235/235 [==============================] - 0s 332us/step - loss: 0.3478 - accuracy: 0.8723 - val_loss: 0.3846 - val_accuracy: 0.8966\n",
      "Epoch 10/150\n",
      "235/235 [==============================] - 0s 346us/step - loss: 0.3204 - accuracy: 0.8723 - val_loss: 0.3601 - val_accuracy: 0.9052\n",
      "Epoch 11/150\n",
      "235/235 [==============================] - 0s 342us/step - loss: 0.3156 - accuracy: 0.8553 - val_loss: 0.3395 - val_accuracy: 0.9052\n",
      "Epoch 12/150\n",
      "235/235 [==============================] - 0s 341us/step - loss: 0.3153 - accuracy: 0.8851 - val_loss: 0.3259 - val_accuracy: 0.9052\n",
      "Epoch 13/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.2899 - accuracy: 0.8809 - val_loss: 0.3112 - val_accuracy: 0.9052\n",
      "Epoch 14/150\n",
      "235/235 [==============================] - 0s 327us/step - loss: 0.2721 - accuracy: 0.8979 - val_loss: 0.2970 - val_accuracy: 0.9052\n",
      "Epoch 15/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.2723 - accuracy: 0.8979 - val_loss: 0.2874 - val_accuracy: 0.9138\n",
      "Epoch 16/150\n",
      "235/235 [==============================] - 0s 327us/step - loss: 0.2684 - accuracy: 0.8766 - val_loss: 0.2761 - val_accuracy: 0.9138\n",
      "Epoch 17/150\n",
      "235/235 [==============================] - 0s 301us/step - loss: 0.2695 - accuracy: 0.8894 - val_loss: 0.2651 - val_accuracy: 0.9138\n",
      "Epoch 18/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.2606 - accuracy: 0.8766 - val_loss: 0.2589 - val_accuracy: 0.9138\n",
      "Epoch 19/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.2277 - accuracy: 0.9106 - val_loss: 0.2520 - val_accuracy: 0.9138\n",
      "Epoch 20/150\n",
      "235/235 [==============================] - 0s 302us/step - loss: 0.2529 - accuracy: 0.9021 - val_loss: 0.2408 - val_accuracy: 0.9138\n",
      "Epoch 21/150\n",
      "235/235 [==============================] - 0s 298us/step - loss: 0.2346 - accuracy: 0.9106 - val_loss: 0.2427 - val_accuracy: 0.9138\n",
      "Epoch 22/150\n",
      "235/235 [==============================] - 0s 316us/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.2411 - val_accuracy: 0.9224\n",
      "Epoch 23/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.2124 - accuracy: 0.9064 - val_loss: 0.2273 - val_accuracy: 0.9310\n",
      "Epoch 24/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.2151 - accuracy: 0.9234 - val_loss: 0.2169 - val_accuracy: 0.9310\n",
      "Epoch 25/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.2037 - accuracy: 0.9149 - val_loss: 0.2122 - val_accuracy: 0.9310\n",
      "Epoch 26/150\n",
      "235/235 [==============================] - 0s 330us/step - loss: 0.2118 - accuracy: 0.9277 - val_loss: 0.2177 - val_accuracy: 0.9310\n",
      "Epoch 27/150\n",
      "235/235 [==============================] - 0s 293us/step - loss: 0.1918 - accuracy: 0.9191 - val_loss: 0.1985 - val_accuracy: 0.9310\n",
      "Epoch 28/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.2056 - accuracy: 0.9277 - val_loss: 0.2008 - val_accuracy: 0.9310\n",
      "Epoch 29/150\n",
      "235/235 [==============================] - 0s 294us/step - loss: 0.1940 - accuracy: 0.9106 - val_loss: 0.1951 - val_accuracy: 0.9310\n",
      "Epoch 30/150\n",
      "235/235 [==============================] - 0s 344us/step - loss: 0.2082 - accuracy: 0.9191 - val_loss: 0.1877 - val_accuracy: 0.9310\n",
      "Epoch 31/150\n",
      "235/235 [==============================] - 0s 266us/step - loss: 0.1923 - accuracy: 0.9319 - val_loss: 0.1893 - val_accuracy: 0.9310\n",
      "Epoch 32/150\n",
      "235/235 [==============================] - 0s 273us/step - loss: 0.1830 - accuracy: 0.9191 - val_loss: 0.1746 - val_accuracy: 0.9397\n",
      "Epoch 33/150\n",
      "235/235 [==============================] - 0s 350us/step - loss: 0.1938 - accuracy: 0.9191 - val_loss: 0.1807 - val_accuracy: 0.9397\n",
      "Epoch 34/150\n",
      "235/235 [==============================] - 0s 262us/step - loss: 0.1825 - accuracy: 0.9277 - val_loss: 0.1782 - val_accuracy: 0.9397\n",
      "Epoch 35/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.1854 - accuracy: 0.9362 - val_loss: 0.1742 - val_accuracy: 0.9397\n",
      "Epoch 36/150\n",
      "235/235 [==============================] - 0s 327us/step - loss: 0.1578 - accuracy: 0.9489 - val_loss: 0.1689 - val_accuracy: 0.9483\n",
      "Epoch 37/150\n",
      "235/235 [==============================] - 0s 324us/step - loss: 0.1860 - accuracy: 0.9191 - val_loss: 0.1619 - val_accuracy: 0.9483\n",
      "Epoch 38/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.1702 - accuracy: 0.9362 - val_loss: 0.1528 - val_accuracy: 0.9655\n",
      "Epoch 39/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.1802 - accuracy: 0.9234 - val_loss: 0.1639 - val_accuracy: 0.9483\n",
      "Epoch 40/150\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.93 - 0s 332us/step - loss: 0.1700 - accuracy: 0.9319 - val_loss: 0.1659 - val_accuracy: 0.9483\n",
      "Epoch 41/150\n",
      "235/235 [==============================] - 0s 325us/step - loss: 0.1616 - accuracy: 0.9362 - val_loss: 0.1621 - val_accuracy: 0.9569\n",
      "Epoch 42/150\n",
      "235/235 [==============================] - 0s 285us/step - loss: 0.1541 - accuracy: 0.9447 - val_loss: 0.1488 - val_accuracy: 0.9655\n",
      "Epoch 43/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.1699 - accuracy: 0.9319 - val_loss: 0.1445 - val_accuracy: 0.9655\n",
      "Epoch 44/150\n",
      "235/235 [==============================] - 0s 337us/step - loss: 0.1497 - accuracy: 0.9234 - val_loss: 0.1416 - val_accuracy: 0.9655\n",
      "Epoch 45/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.1784 - accuracy: 0.9277 - val_loss: 0.1434 - val_accuracy: 0.9741\n",
      "Epoch 46/150\n",
      "235/235 [==============================] - 0s 342us/step - loss: 0.1481 - accuracy: 0.9362 - val_loss: 0.1477 - val_accuracy: 0.9655\n",
      "Epoch 47/150\n",
      "235/235 [==============================] - 0s 325us/step - loss: 0.1585 - accuracy: 0.9319 - val_loss: 0.1451 - val_accuracy: 0.9655\n",
      "Epoch 48/150\n",
      "235/235 [==============================] - 0s 234us/step - loss: 0.1420 - accuracy: 0.9362 - val_loss: 0.1406 - val_accuracy: 0.9655\n",
      "Epoch 49/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.1344 - accuracy: 0.9660 - val_loss: 0.1361 - val_accuracy: 0.9741\n",
      "Epoch 50/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.1437 - accuracy: 0.9404 - val_loss: 0.1302 - val_accuracy: 0.9741\n",
      "Epoch 51/150\n",
      "235/235 [==============================] - 0s 349us/step - loss: 0.1344 - accuracy: 0.9489 - val_loss: 0.1295 - val_accuracy: 0.9828\n",
      "Epoch 52/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.1609 - accuracy: 0.9362 - val_loss: 0.1261 - val_accuracy: 0.9828\n",
      "Epoch 53/150\n",
      "235/235 [==============================] - 0s 316us/step - loss: 0.1436 - accuracy: 0.9404 - val_loss: 0.1233 - val_accuracy: 0.9828\n",
      "Epoch 54/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.1224 - accuracy: 0.9660 - val_loss: 0.1228 - val_accuracy: 0.9828\n",
      "Epoch 55/150\n",
      "235/235 [==============================] - 0s 284us/step - loss: 0.1330 - accuracy: 0.9617 - val_loss: 0.1216 - val_accuracy: 0.9741\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 334us/step - loss: 0.1363 - accuracy: 0.9447 - val_loss: 0.1234 - val_accuracy: 0.9741\n",
      "Epoch 57/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.1216 - accuracy: 0.9617 - val_loss: 0.1183 - val_accuracy: 0.9741\n",
      "Epoch 58/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.1476 - accuracy: 0.9447 - val_loss: 0.1224 - val_accuracy: 0.9828\n",
      "Epoch 59/150\n",
      "235/235 [==============================] - 0s 309us/step - loss: 0.1284 - accuracy: 0.9489 - val_loss: 0.1174 - val_accuracy: 0.9741\n",
      "Epoch 60/150\n",
      "235/235 [==============================] - 0s 325us/step - loss: 0.1287 - accuracy: 0.9574 - val_loss: 0.1172 - val_accuracy: 0.9741\n",
      "Epoch 61/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.1496 - accuracy: 0.9532 - val_loss: 0.1211 - val_accuracy: 0.9741\n",
      "Epoch 62/150\n",
      "235/235 [==============================] - 0s 283us/step - loss: 0.1449 - accuracy: 0.9319 - val_loss: 0.1205 - val_accuracy: 0.9741\n",
      "Epoch 63/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.1209 - accuracy: 0.9617 - val_loss: 0.1193 - val_accuracy: 0.9741\n",
      "Epoch 64/150\n",
      "235/235 [==============================] - 0s 332us/step - loss: 0.1035 - accuracy: 0.9745 - val_loss: 0.1121 - val_accuracy: 0.9741\n",
      "Epoch 65/150\n",
      "235/235 [==============================] - 0s 290us/step - loss: 0.1087 - accuracy: 0.9617 - val_loss: 0.1090 - val_accuracy: 0.9741\n",
      "Epoch 66/150\n",
      "235/235 [==============================] - 0s 300us/step - loss: 0.1187 - accuracy: 0.9574 - val_loss: 0.1074 - val_accuracy: 0.9828\n",
      "Epoch 67/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.1368 - accuracy: 0.9447 - val_loss: 0.1158 - val_accuracy: 0.9741\n",
      "Epoch 68/150\n",
      "235/235 [==============================] - 0s 334us/step - loss: 0.1346 - accuracy: 0.9532 - val_loss: 0.1225 - val_accuracy: 0.9741\n",
      "Epoch 69/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.1368 - accuracy: 0.9489 - val_loss: 0.1089 - val_accuracy: 0.9741\n",
      "Epoch 70/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.1182 - accuracy: 0.9532 - val_loss: 0.1064 - val_accuracy: 0.9741\n",
      "Epoch 71/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.1194 - accuracy: 0.9532 - val_loss: 0.1074 - val_accuracy: 0.9741\n",
      "Epoch 72/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.1363 - accuracy: 0.9447 - val_loss: 0.1214 - val_accuracy: 0.9741\n",
      "Epoch 73/150\n",
      "235/235 [==============================] - 0s 313us/step - loss: 0.1200 - accuracy: 0.9617 - val_loss: 0.1104 - val_accuracy: 0.9741\n",
      "Epoch 74/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.1275 - accuracy: 0.9574 - val_loss: 0.1132 - val_accuracy: 0.9828\n",
      "Epoch 75/150\n",
      "235/235 [==============================] - 0s 276us/step - loss: 0.1067 - accuracy: 0.9660 - val_loss: 0.1093 - val_accuracy: 0.9741\n",
      "Epoch 76/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.1178 - accuracy: 0.9574 - val_loss: 0.1050 - val_accuracy: 0.9741\n",
      "Epoch 77/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.1142 - accuracy: 0.9574 - val_loss: 0.1083 - val_accuracy: 0.9828\n",
      "Epoch 78/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.1008 - accuracy: 0.9702 - val_loss: 0.1065 - val_accuracy: 0.9741\n",
      "Epoch 79/150\n",
      "235/235 [==============================] - 0s 318us/step - loss: 0.1125 - accuracy: 0.9574 - val_loss: 0.1058 - val_accuracy: 0.9828\n",
      "Epoch 80/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.1084 - accuracy: 0.9702 - val_loss: 0.1052 - val_accuracy: 0.9741\n",
      "Epoch 81/150\n",
      "235/235 [==============================] - 0s 296us/step - loss: 0.1198 - accuracy: 0.9489 - val_loss: 0.1030 - val_accuracy: 0.9828\n",
      "Epoch 82/150\n",
      "235/235 [==============================] - 0s 333us/step - loss: 0.1123 - accuracy: 0.9660 - val_loss: 0.0993 - val_accuracy: 0.9828\n",
      "Epoch 83/150\n",
      "235/235 [==============================] - 0s 337us/step - loss: 0.1284 - accuracy: 0.9447 - val_loss: 0.1020 - val_accuracy: 0.9828\n",
      "Epoch 84/150\n",
      "235/235 [==============================] - 0s 271us/step - loss: 0.1202 - accuracy: 0.9532 - val_loss: 0.1047 - val_accuracy: 0.9828\n",
      "Epoch 85/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.1113 - accuracy: 0.9617 - val_loss: 0.1087 - val_accuracy: 0.9828\n",
      "Epoch 86/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.0927 - accuracy: 0.9745 - val_loss: 0.1047 - val_accuracy: 0.9741\n",
      "Epoch 87/150\n",
      "235/235 [==============================] - 0s 339us/step - loss: 0.0934 - accuracy: 0.9745 - val_loss: 0.1052 - val_accuracy: 0.9741\n",
      "Epoch 88/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.1172 - accuracy: 0.9617 - val_loss: 0.1055 - val_accuracy: 0.9741\n",
      "Epoch 89/150\n",
      "235/235 [==============================] - 0s 334us/step - loss: 0.0883 - accuracy: 0.9745 - val_loss: 0.1069 - val_accuracy: 0.9741\n",
      "Epoch 90/150\n",
      "235/235 [==============================] - 0s 317us/step - loss: 0.0974 - accuracy: 0.9660 - val_loss: 0.1041 - val_accuracy: 0.9741\n",
      "Epoch 91/150\n",
      "235/235 [==============================] - 0s 290us/step - loss: 0.1031 - accuracy: 0.9660 - val_loss: 0.1025 - val_accuracy: 0.9741\n",
      "Epoch 92/150\n",
      "235/235 [==============================] - 0s 335us/step - loss: 0.1024 - accuracy: 0.9532 - val_loss: 0.1023 - val_accuracy: 0.9741\n",
      "Epoch 93/150\n",
      "235/235 [==============================] - 0s 332us/step - loss: 0.1038 - accuracy: 0.9702 - val_loss: 0.1064 - val_accuracy: 0.9655\n",
      "Epoch 94/150\n",
      "235/235 [==============================] - 0s 285us/step - loss: 0.1327 - accuracy: 0.9489 - val_loss: 0.1031 - val_accuracy: 0.9741\n",
      "Epoch 95/150\n",
      "235/235 [==============================] - 0s 309us/step - loss: 0.1074 - accuracy: 0.9702 - val_loss: 0.1098 - val_accuracy: 0.9655\n",
      "Epoch 96/150\n",
      "235/235 [==============================] - 0s 295us/step - loss: 0.1122 - accuracy: 0.9532 - val_loss: 0.1093 - val_accuracy: 0.9655\n",
      "Epoch 97/150\n",
      "235/235 [==============================] - 0s 325us/step - loss: 0.1016 - accuracy: 0.9574 - val_loss: 0.1038 - val_accuracy: 0.9741\n",
      "Epoch 98/150\n",
      "235/235 [==============================] - 0s 345us/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.0969 - val_accuracy: 0.9741\n",
      "Epoch 99/150\n",
      "235/235 [==============================] - 0s 298us/step - loss: 0.1032 - accuracy: 0.9574 - val_loss: 0.0922 - val_accuracy: 0.9741\n",
      "Epoch 100/150\n",
      "235/235 [==============================] - 0s 309us/step - loss: 0.0869 - accuracy: 0.9702 - val_loss: 0.0892 - val_accuracy: 0.9828\n",
      "Epoch 101/150\n",
      "235/235 [==============================] - 0s 340us/step - loss: 0.1394 - accuracy: 0.9447 - val_loss: 0.0998 - val_accuracy: 0.9741\n",
      "Epoch 102/150\n",
      "235/235 [==============================] - 0s 240us/step - loss: 0.1294 - accuracy: 0.9532 - val_loss: 0.0976 - val_accuracy: 0.9828\n",
      "Epoch 103/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.1049 - accuracy: 0.9574 - val_loss: 0.0931 - val_accuracy: 0.9828\n",
      "Epoch 104/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.1156 - accuracy: 0.9234 - val_loss: 0.0915 - val_accuracy: 0.9828\n",
      "Epoch 105/150\n",
      "235/235 [==============================] - 0s 257us/step - loss: 0.1092 - accuracy: 0.9617 - val_loss: 0.0869 - val_accuracy: 0.9741\n",
      "Epoch 106/150\n",
      "235/235 [==============================] - 0s 222us/step - loss: 0.1202 - accuracy: 0.9660 - val_loss: 0.0873 - val_accuracy: 0.9828\n",
      "Epoch 107/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0961 - accuracy: 0.9745 - val_loss: 0.0904 - val_accuracy: 0.9741\n",
      "Epoch 108/150\n",
      "235/235 [==============================] - 0s 330us/step - loss: 0.1103 - accuracy: 0.9532 - val_loss: 0.0913 - val_accuracy: 0.9828\n",
      "Epoch 109/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.0849 - accuracy: 0.9787 - val_loss: 0.0918 - val_accuracy: 0.9741\n",
      "Epoch 110/150\n",
      "235/235 [==============================] - 0s 287us/step - loss: 0.1117 - accuracy: 0.9574 - val_loss: 0.0931 - val_accuracy: 0.9741\n",
      "Epoch 111/150\n",
      "235/235 [==============================] - 0s 304us/step - loss: 0.1042 - accuracy: 0.9660 - val_loss: 0.0885 - val_accuracy: 0.9741\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 311us/step - loss: 0.0978 - accuracy: 0.9617 - val_loss: 0.0912 - val_accuracy: 0.9741\n",
      "Epoch 113/150\n",
      "235/235 [==============================] - 0s 306us/step - loss: 0.0763 - accuracy: 0.9830 - val_loss: 0.0884 - val_accuracy: 0.9741\n",
      "Epoch 114/150\n",
      "235/235 [==============================] - 0s 341us/step - loss: 0.0799 - accuracy: 0.9745 - val_loss: 0.0844 - val_accuracy: 0.9741\n",
      "Epoch 115/150\n",
      "235/235 [==============================] - 0s 357us/step - loss: 0.0828 - accuracy: 0.9702 - val_loss: 0.0866 - val_accuracy: 0.9828\n",
      "Epoch 116/150\n",
      "235/235 [==============================] - 0s 267us/step - loss: 0.1005 - accuracy: 0.9574 - val_loss: 0.0861 - val_accuracy: 0.9741\n",
      "Epoch 117/150\n",
      "235/235 [==============================] - 0s 320us/step - loss: 0.0923 - accuracy: 0.9745 - val_loss: 0.0854 - val_accuracy: 0.9741\n",
      "Epoch 118/150\n",
      "235/235 [==============================] - 0s 321us/step - loss: 0.0847 - accuracy: 0.9660 - val_loss: 0.0866 - val_accuracy: 0.9741\n",
      "Epoch 119/150\n",
      "235/235 [==============================] - 0s 335us/step - loss: 0.0971 - accuracy: 0.9617 - val_loss: 0.0808 - val_accuracy: 0.9741\n",
      "Epoch 120/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.1195 - accuracy: 0.9404 - val_loss: 0.0905 - val_accuracy: 0.9741\n",
      "Epoch 121/150\n",
      "235/235 [==============================] - 0s 335us/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.0894 - val_accuracy: 0.9828\n",
      "Epoch 122/150\n",
      "235/235 [==============================] - 0s 335us/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 0.0861 - val_accuracy: 0.9828\n",
      "Epoch 123/150\n",
      "235/235 [==============================] - 0s 348us/step - loss: 0.0758 - accuracy: 0.9787 - val_loss: 0.0885 - val_accuracy: 0.9828\n",
      "Epoch 124/150\n",
      "235/235 [==============================] - 0s 343us/step - loss: 0.0853 - accuracy: 0.9617 - val_loss: 0.0856 - val_accuracy: 0.9828\n",
      "Epoch 125/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0759 - accuracy: 0.9702 - val_loss: 0.0840 - val_accuracy: 0.9828\n",
      "Epoch 126/150\n",
      "235/235 [==============================] - 0s 311us/step - loss: 0.0840 - accuracy: 0.9617 - val_loss: 0.0888 - val_accuracy: 0.9828\n",
      "Epoch 127/150\n",
      "235/235 [==============================] - 0s 335us/step - loss: 0.0799 - accuracy: 0.9745 - val_loss: 0.0858 - val_accuracy: 0.9828\n",
      "Epoch 128/150\n",
      "235/235 [==============================] - 0s 326us/step - loss: 0.0713 - accuracy: 0.9787 - val_loss: 0.0849 - val_accuracy: 0.9828\n",
      "Epoch 129/150\n",
      "235/235 [==============================] - 0s 269us/step - loss: 0.0841 - accuracy: 0.9702 - val_loss: 0.0848 - val_accuracy: 0.9741\n",
      "Epoch 130/150\n",
      "235/235 [==============================] - 0s 298us/step - loss: 0.1024 - accuracy: 0.9617 - val_loss: 0.0901 - val_accuracy: 0.9828\n",
      "Epoch 131/150\n",
      "235/235 [==============================] - 0s 322us/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.0878 - val_accuracy: 0.9828\n",
      "Epoch 132/150\n",
      "235/235 [==============================] - 0s 285us/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0917 - val_accuracy: 0.9828\n",
      "Epoch 133/150\n",
      "235/235 [==============================] - 0s 334us/step - loss: 0.0931 - accuracy: 0.9617 - val_loss: 0.0932 - val_accuracy: 0.9828\n",
      "Epoch 134/150\n",
      "235/235 [==============================] - 0s 340us/step - loss: 0.1056 - accuracy: 0.9617 - val_loss: 0.0936 - val_accuracy: 0.9741\n",
      "Epoch 135/150\n",
      "235/235 [==============================] - 0s 328us/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 0.0936 - val_accuracy: 0.9741\n",
      "Epoch 136/150\n",
      "235/235 [==============================] - 0s 342us/step - loss: 0.0826 - accuracy: 0.9660 - val_loss: 0.0864 - val_accuracy: 0.9741\n",
      "Epoch 137/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0850 - accuracy: 0.9787 - val_loss: 0.0811 - val_accuracy: 0.9828\n",
      "Epoch 138/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0825 - accuracy: 0.9745 - val_loss: 0.0814 - val_accuracy: 0.9828\n",
      "Epoch 139/150\n",
      "235/235 [==============================] - 0s 337us/step - loss: 0.0733 - accuracy: 0.9745 - val_loss: 0.0819 - val_accuracy: 0.9828\n",
      "Epoch 140/150\n",
      "235/235 [==============================] - 0s 341us/step - loss: 0.0830 - accuracy: 0.9489 - val_loss: 0.0848 - val_accuracy: 0.9828\n",
      "Epoch 141/150\n",
      "235/235 [==============================] - 0s 246us/step - loss: 0.0803 - accuracy: 0.9702 - val_loss: 0.0888 - val_accuracy: 0.9741\n",
      "Epoch 142/150\n",
      "235/235 [==============================] - 0s 288us/step - loss: 0.0675 - accuracy: 0.9830 - val_loss: 0.0877 - val_accuracy: 0.9741\n",
      "Epoch 143/150\n",
      "235/235 [==============================] - 0s 280us/step - loss: 0.1110 - accuracy: 0.9702 - val_loss: 0.0892 - val_accuracy: 0.9741\n",
      "Epoch 144/150\n",
      "235/235 [==============================] - 0s 303us/step - loss: 0.0866 - accuracy: 0.9660 - val_loss: 0.0908 - val_accuracy: 0.9741\n",
      "Epoch 145/150\n",
      "235/235 [==============================] - 0s 323us/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 0.0838 - val_accuracy: 0.9828\n",
      "Epoch 146/150\n",
      "235/235 [==============================] - 0s 319us/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.0835 - val_accuracy: 0.9741\n",
      "Epoch 147/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0943 - accuracy: 0.9745 - val_loss: 0.0817 - val_accuracy: 0.9828\n",
      "Epoch 148/150\n",
      "235/235 [==============================] - 0s 331us/step - loss: 0.0770 - accuracy: 0.9660 - val_loss: 0.0858 - val_accuracy: 0.9828\n",
      "Epoch 149/150\n",
      "235/235 [==============================] - 0s 291us/step - loss: 0.0639 - accuracy: 0.9830 - val_loss: 0.0838 - val_accuracy: 0.9828\n",
      "Epoch 150/150\n",
      "235/235 [==============================] - 0s 336us/step - loss: 0.1085 - accuracy: 0.9745 - val_loss: 0.0834 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2693049d448>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_3 (Dropout)          (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 34)                1190      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 280       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,479\n",
      "Trainable params: 1,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(34,)))\n",
    "model.add(Dense(34,  kernel_initializer='normal', activation = 'relu'))\n",
    "model.add(Dense(8,  kernel_initializer='normal', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/150\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5660 - val_loss: 0.6923 - val_accuracy: 0.7069\n",
      "Epoch 2/150\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.6909 - accuracy: 0.7574 - val_loss: 0.6918 - val_accuracy: 0.5862\n",
      "Epoch 3/150\n",
      "235/235 [==============================] - 0s 83us/step - loss: 0.6878 - accuracy: 0.7872 - val_loss: 0.6912 - val_accuracy: 0.5862\n",
      "Epoch 4/150\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.6827 - accuracy: 0.7787 - val_loss: 0.6909 - val_accuracy: 0.5690\n",
      "Epoch 5/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.6750 - accuracy: 0.7702 - val_loss: 0.6909 - val_accuracy: 0.5776\n",
      "Epoch 6/150\n",
      "235/235 [==============================] - 0s 148us/step - loss: 0.6625 - accuracy: 0.7787 - val_loss: 0.6884 - val_accuracy: 0.5862\n",
      "Epoch 7/150\n",
      "235/235 [==============================] - 0s 99us/step - loss: 0.6458 - accuracy: 0.7787 - val_loss: 0.6842 - val_accuracy: 0.5776\n",
      "Epoch 8/150\n",
      "235/235 [==============================] - 0s 82us/step - loss: 0.6291 - accuracy: 0.7617 - val_loss: 0.6765 - val_accuracy: 0.5776\n",
      "Epoch 9/150\n",
      "235/235 [==============================] - 0s 101us/step - loss: 0.5997 - accuracy: 0.7915 - val_loss: 0.6688 - val_accuracy: 0.5948\n",
      "Epoch 10/150\n",
      "235/235 [==============================] - 0s 121us/step - loss: 0.5674 - accuracy: 0.7915 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.5399 - accuracy: 0.7957 - val_loss: 0.6343 - val_accuracy: 0.8103\n",
      "Epoch 12/150\n",
      "235/235 [==============================] - 0s 113us/step - loss: 0.5111 - accuracy: 0.8043 - val_loss: 0.6127 - val_accuracy: 0.8190\n",
      "Epoch 13/150\n",
      "235/235 [==============================] - 0s 107us/step - loss: 0.4800 - accuracy: 0.8170 - val_loss: 0.5845 - val_accuracy: 0.8362\n",
      "Epoch 14/150\n",
      "235/235 [==============================] - 0s 99us/step - loss: 0.4605 - accuracy: 0.8128 - val_loss: 0.5518 - val_accuracy: 0.8448\n",
      "Epoch 15/150\n",
      "235/235 [==============================] - 0s 96us/step - loss: 0.4243 - accuracy: 0.8468 - val_loss: 0.5174 - val_accuracy: 0.8707\n",
      "Epoch 16/150\n",
      "235/235 [==============================] - 0s 76us/step - loss: 0.3994 - accuracy: 0.8596 - val_loss: 0.4789 - val_accuracy: 0.8879\n",
      "Epoch 17/150\n",
      "235/235 [==============================] - 0s 113us/step - loss: 0.3694 - accuracy: 0.8723 - val_loss: 0.4516 - val_accuracy: 0.8966\n",
      "Epoch 18/150\n",
      "235/235 [==============================] - 0s 122us/step - loss: 0.3501 - accuracy: 0.8681 - val_loss: 0.4254 - val_accuracy: 0.8966\n",
      "Epoch 19/150\n",
      "235/235 [==============================] - 0s 95us/step - loss: 0.3271 - accuracy: 0.8894 - val_loss: 0.3989 - val_accuracy: 0.9052\n",
      "Epoch 20/150\n",
      "235/235 [==============================] - 0s 92us/step - loss: 0.3220 - accuracy: 0.8894 - val_loss: 0.3821 - val_accuracy: 0.9052\n",
      "Epoch 21/150\n",
      "235/235 [==============================] - 0s 72us/step - loss: 0.3075 - accuracy: 0.8681 - val_loss: 0.3587 - val_accuracy: 0.9138\n",
      "Epoch 22/150\n",
      "235/235 [==============================] - 0s 147us/step - loss: 0.2911 - accuracy: 0.8894 - val_loss: 0.3426 - val_accuracy: 0.9138\n",
      "Epoch 23/150\n",
      "235/235 [==============================] - 0s 141us/step - loss: 0.2706 - accuracy: 0.8979 - val_loss: 0.3290 - val_accuracy: 0.9138\n",
      "Epoch 24/150\n",
      "235/235 [==============================] - 0s 150us/step - loss: 0.2618 - accuracy: 0.8979 - val_loss: 0.3072 - val_accuracy: 0.9138\n",
      "Epoch 25/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.2598 - accuracy: 0.8936 - val_loss: 0.2841 - val_accuracy: 0.9138\n",
      "Epoch 26/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.2370 - accuracy: 0.9106 - val_loss: 0.2660 - val_accuracy: 0.9138\n",
      "Epoch 27/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.2458 - accuracy: 0.8979 - val_loss: 0.2480 - val_accuracy: 0.9138\n",
      "Epoch 28/150\n",
      "235/235 [==============================] - 0s 130us/step - loss: 0.2286 - accuracy: 0.9149 - val_loss: 0.2323 - val_accuracy: 0.9310\n",
      "Epoch 29/150\n",
      "235/235 [==============================] - 0s 140us/step - loss: 0.2096 - accuracy: 0.9277 - val_loss: 0.2246 - val_accuracy: 0.9224\n",
      "Epoch 30/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.2122 - accuracy: 0.9149 - val_loss: 0.2240 - val_accuracy: 0.9310\n",
      "Epoch 31/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.2067 - accuracy: 0.9234 - val_loss: 0.2179 - val_accuracy: 0.9310\n",
      "Epoch 32/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1898 - accuracy: 0.9404 - val_loss: 0.2012 - val_accuracy: 0.9483\n",
      "Epoch 33/150\n",
      "235/235 [==============================] - 0s 147us/step - loss: 0.2099 - accuracy: 0.9106 - val_loss: 0.2037 - val_accuracy: 0.9397\n",
      "Epoch 34/150\n",
      "235/235 [==============================] - 0s 129us/step - loss: 0.1910 - accuracy: 0.9106 - val_loss: 0.1897 - val_accuracy: 0.9397\n",
      "Epoch 35/150\n",
      "235/235 [==============================] - 0s 145us/step - loss: 0.1790 - accuracy: 0.9362 - val_loss: 0.1746 - val_accuracy: 0.9397\n",
      "Epoch 36/150\n",
      "235/235 [==============================] - 0s 134us/step - loss: 0.1878 - accuracy: 0.9234 - val_loss: 0.1664 - val_accuracy: 0.9397\n",
      "Epoch 37/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1799 - accuracy: 0.9319 - val_loss: 0.1574 - val_accuracy: 0.9483\n",
      "Epoch 38/150\n",
      "235/235 [==============================] - 0s 127us/step - loss: 0.2030 - accuracy: 0.9106 - val_loss: 0.1522 - val_accuracy: 0.9483\n",
      "Epoch 39/150\n",
      "235/235 [==============================] - 0s 155us/step - loss: 0.1717 - accuracy: 0.9319 - val_loss: 0.1536 - val_accuracy: 0.9483\n",
      "Epoch 40/150\n",
      "235/235 [==============================] - 0s 183us/step - loss: 0.1466 - accuracy: 0.9447 - val_loss: 0.1519 - val_accuracy: 0.9569\n",
      "Epoch 41/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.1664 - accuracy: 0.9362 - val_loss: 0.1489 - val_accuracy: 0.9569\n",
      "Epoch 42/150\n",
      "235/235 [==============================] - 0s 137us/step - loss: 0.1593 - accuracy: 0.9362 - val_loss: 0.1462 - val_accuracy: 0.9569\n",
      "Epoch 43/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.1694 - accuracy: 0.9404 - val_loss: 0.1489 - val_accuracy: 0.9483\n",
      "Epoch 44/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.1587 - accuracy: 0.9362 - val_loss: 0.1392 - val_accuracy: 0.9655\n",
      "Epoch 45/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.1411 - accuracy: 0.9574 - val_loss: 0.1277 - val_accuracy: 0.9655\n",
      "Epoch 46/150\n",
      "235/235 [==============================] - 0s 128us/step - loss: 0.1695 - accuracy: 0.9447 - val_loss: 0.1190 - val_accuracy: 0.9741\n",
      "Epoch 47/150\n",
      "235/235 [==============================] - 0s 137us/step - loss: 0.1495 - accuracy: 0.9362 - val_loss: 0.1205 - val_accuracy: 0.9741\n",
      "Epoch 48/150\n",
      "235/235 [==============================] - 0s 126us/step - loss: 0.1443 - accuracy: 0.9319 - val_loss: 0.1181 - val_accuracy: 0.9741\n",
      "Epoch 49/150\n",
      "235/235 [==============================] - 0s 150us/step - loss: 0.1485 - accuracy: 0.9447 - val_loss: 0.1124 - val_accuracy: 0.9828\n",
      "Epoch 50/150\n",
      "235/235 [==============================] - 0s 147us/step - loss: 0.1398 - accuracy: 0.9447 - val_loss: 0.1143 - val_accuracy: 0.9828\n",
      "Epoch 51/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.1406 - accuracy: 0.9532 - val_loss: 0.1140 - val_accuracy: 0.9828\n",
      "Epoch 52/150\n",
      "235/235 [==============================] - 0s 134us/step - loss: 0.1498 - accuracy: 0.9404 - val_loss: 0.1107 - val_accuracy: 0.9828\n",
      "Epoch 53/150\n",
      "235/235 [==============================] - 0s 137us/step - loss: 0.1320 - accuracy: 0.9362 - val_loss: 0.1139 - val_accuracy: 0.9828\n",
      "Epoch 54/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1510 - accuracy: 0.9447 - val_loss: 0.1079 - val_accuracy: 0.9828\n",
      "Epoch 55/150\n",
      "235/235 [==============================] - 0s 140us/step - loss: 0.1322 - accuracy: 0.9447 - val_loss: 0.1001 - val_accuracy: 0.9828\n",
      "Epoch 56/150\n",
      "235/235 [==============================] - 0s 148us/step - loss: 0.1365 - accuracy: 0.9404 - val_loss: 0.0969 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "235/235 [==============================] - 0s 140us/step - loss: 0.1299 - accuracy: 0.9447 - val_loss: 0.0964 - val_accuracy: 0.9828\n",
      "Epoch 58/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.1546 - accuracy: 0.9404 - val_loss: 0.0983 - val_accuracy: 0.9828\n",
      "Epoch 59/150\n",
      "235/235 [==============================] - 0s 130us/step - loss: 0.1522 - accuracy: 0.9404 - val_loss: 0.0977 - val_accuracy: 0.9828\n",
      "Epoch 60/150\n",
      "235/235 [==============================] - 0s 132us/step - loss: 0.1339 - accuracy: 0.9447 - val_loss: 0.1001 - val_accuracy: 0.9828\n",
      "Epoch 61/150\n",
      "235/235 [==============================] - 0s 127us/step - loss: 0.1386 - accuracy: 0.9319 - val_loss: 0.1024 - val_accuracy: 0.9828\n",
      "Epoch 62/150\n",
      "235/235 [==============================] - 0s 134us/step - loss: 0.1355 - accuracy: 0.9532 - val_loss: 0.1004 - val_accuracy: 0.9828\n",
      "Epoch 63/150\n",
      "235/235 [==============================] - 0s 153us/step - loss: 0.1204 - accuracy: 0.9532 - val_loss: 0.0985 - val_accuracy: 0.9828\n",
      "Epoch 64/150\n",
      "235/235 [==============================] - 0s 151us/step - loss: 0.1249 - accuracy: 0.9574 - val_loss: 0.0989 - val_accuracy: 0.9828\n",
      "Epoch 65/150\n",
      "235/235 [==============================] - 0s 156us/step - loss: 0.1251 - accuracy: 0.9617 - val_loss: 0.1003 - val_accuracy: 0.9828\n",
      "Epoch 66/150\n",
      "235/235 [==============================] - 0s 152us/step - loss: 0.1463 - accuracy: 0.9532 - val_loss: 0.0992 - val_accuracy: 0.9828\n",
      "Epoch 67/150\n",
      "235/235 [==============================] - 0s 82us/step - loss: 0.1150 - accuracy: 0.9617 - val_loss: 0.0938 - val_accuracy: 0.9828\n",
      "Epoch 68/150\n",
      "235/235 [==============================] - 0s 88us/step - loss: 0.1253 - accuracy: 0.9574 - val_loss: 0.0903 - val_accuracy: 0.9828\n",
      "Epoch 69/150\n",
      "235/235 [==============================] - 0s 152us/step - loss: 0.1051 - accuracy: 0.9745 - val_loss: 0.0883 - val_accuracy: 0.9828\n",
      "Epoch 70/150\n",
      "235/235 [==============================] - 0s 146us/step - loss: 0.1270 - accuracy: 0.9617 - val_loss: 0.0890 - val_accuracy: 0.9828\n",
      "Epoch 71/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.1258 - accuracy: 0.9532 - val_loss: 0.0812 - val_accuracy: 0.9914\n",
      "Epoch 72/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.1129 - accuracy: 0.9532 - val_loss: 0.0798 - val_accuracy: 0.9914\n",
      "Epoch 73/150\n",
      "235/235 [==============================] - 0s 140us/step - loss: 0.1299 - accuracy: 0.9532 - val_loss: 0.0795 - val_accuracy: 0.9914\n",
      "Epoch 74/150\n",
      "235/235 [==============================] - 0s 132us/step - loss: 0.1099 - accuracy: 0.9702 - val_loss: 0.0803 - val_accuracy: 0.9914\n",
      "Epoch 75/150\n",
      "235/235 [==============================] - 0s 139us/step - loss: 0.1009 - accuracy: 0.9660 - val_loss: 0.0798 - val_accuracy: 0.9914\n",
      "Epoch 76/150\n",
      "235/235 [==============================] - 0s 151us/step - loss: 0.0974 - accuracy: 0.9617 - val_loss: 0.0791 - val_accuracy: 0.9914\n",
      "Epoch 77/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1319 - accuracy: 0.9404 - val_loss: 0.0842 - val_accuracy: 0.9914\n",
      "Epoch 78/150\n",
      "235/235 [==============================] - 0s 151us/step - loss: 0.1042 - accuracy: 0.9574 - val_loss: 0.0858 - val_accuracy: 0.9914\n",
      "Epoch 79/150\n",
      "235/235 [==============================] - 0s 149us/step - loss: 0.1061 - accuracy: 0.9447 - val_loss: 0.0858 - val_accuracy: 0.9828\n",
      "Epoch 80/150\n",
      "235/235 [==============================] - 0s 184us/step - loss: 0.0959 - accuracy: 0.9745 - val_loss: 0.0832 - val_accuracy: 0.9828\n",
      "Epoch 81/150\n",
      "235/235 [==============================] - 0s 156us/step - loss: 0.1127 - accuracy: 0.9617 - val_loss: 0.0779 - val_accuracy: 0.9828\n",
      "Epoch 82/150\n",
      "235/235 [==============================] - 0s 163us/step - loss: 0.0954 - accuracy: 0.9702 - val_loss: 0.0747 - val_accuracy: 0.9828\n",
      "Epoch 83/150\n",
      "235/235 [==============================] - 0s 156us/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.0731 - val_accuracy: 0.9914\n",
      "Epoch 84/150\n",
      "235/235 [==============================] - 0s 148us/step - loss: 0.1056 - accuracy: 0.9574 - val_loss: 0.0738 - val_accuracy: 0.9914\n",
      "Epoch 85/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.0941 - accuracy: 0.9702 - val_loss: 0.0738 - val_accuracy: 0.9914\n",
      "Epoch 86/150\n",
      "235/235 [==============================] - 0s 165us/step - loss: 0.1146 - accuracy: 0.9532 - val_loss: 0.0739 - val_accuracy: 0.9914\n",
      "Epoch 87/150\n",
      "235/235 [==============================] - 0s 141us/step - loss: 0.0941 - accuracy: 0.9702 - val_loss: 0.0736 - val_accuracy: 0.9914\n",
      "Epoch 88/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.0938 - accuracy: 0.9617 - val_loss: 0.0725 - val_accuracy: 0.9828\n",
      "Epoch 89/150\n",
      "235/235 [==============================] - 0s 130us/step - loss: 0.1192 - accuracy: 0.9532 - val_loss: 0.0772 - val_accuracy: 0.9828\n",
      "Epoch 90/150\n",
      "235/235 [==============================] - 0s 147us/step - loss: 0.0904 - accuracy: 0.9660 - val_loss: 0.0734 - val_accuracy: 0.9828\n",
      "Epoch 91/150\n",
      "235/235 [==============================] - 0s 67us/step - loss: 0.0834 - accuracy: 0.9660 - val_loss: 0.0700 - val_accuracy: 0.9828\n",
      "Epoch 92/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1404 - accuracy: 0.9489 - val_loss: 0.0727 - val_accuracy: 0.9828\n",
      "Epoch 93/150\n",
      "235/235 [==============================] - 0s 126us/step - loss: 0.1146 - accuracy: 0.9574 - val_loss: 0.0798 - val_accuracy: 0.9914\n",
      "Epoch 94/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.1075 - accuracy: 0.9447 - val_loss: 0.0771 - val_accuracy: 0.9914\n",
      "Epoch 95/150\n",
      "235/235 [==============================] - 0s 146us/step - loss: 0.1153 - accuracy: 0.9574 - val_loss: 0.0760 - val_accuracy: 0.9828\n",
      "Epoch 96/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.1017 - accuracy: 0.9532 - val_loss: 0.0793 - val_accuracy: 0.9828\n",
      "Epoch 97/150\n",
      "235/235 [==============================] - 0s 139us/step - loss: 0.1113 - accuracy: 0.9574 - val_loss: 0.0815 - val_accuracy: 0.9828\n",
      "Epoch 98/150\n",
      "235/235 [==============================] - 0s 158us/step - loss: 0.1222 - accuracy: 0.9574 - val_loss: 0.0825 - val_accuracy: 0.9828\n",
      "Epoch 99/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.0825 - val_accuracy: 0.9828\n",
      "Epoch 100/150\n",
      "235/235 [==============================] - 0s 123us/step - loss: 0.1039 - accuracy: 0.9617 - val_loss: 0.0746 - val_accuracy: 0.9828\n",
      "Epoch 101/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.0873 - accuracy: 0.9702 - val_loss: 0.0658 - val_accuracy: 0.9828\n",
      "Epoch 102/150\n",
      "235/235 [==============================] - 0s 135us/step - loss: 0.1015 - accuracy: 0.9574 - val_loss: 0.0659 - val_accuracy: 0.9828\n",
      "Epoch 103/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.1038 - accuracy: 0.9702 - val_loss: 0.0685 - val_accuracy: 0.9828\n",
      "Epoch 104/150\n",
      "235/235 [==============================] - 0s 146us/step - loss: 0.1158 - accuracy: 0.9532 - val_loss: 0.0707 - val_accuracy: 0.9914\n",
      "Epoch 105/150\n",
      "235/235 [==============================] - 0s 121us/step - loss: 0.0842 - accuracy: 0.9660 - val_loss: 0.0811 - val_accuracy: 0.9914\n",
      "Epoch 106/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.0841 - accuracy: 0.9702 - val_loss: 0.0773 - val_accuracy: 0.9914\n",
      "Epoch 107/150\n",
      "235/235 [==============================] - 0s 137us/step - loss: 0.1013 - accuracy: 0.9702 - val_loss: 0.0704 - val_accuracy: 0.9914\n",
      "Epoch 108/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.0683 - val_accuracy: 0.9828\n",
      "Epoch 109/150\n",
      "235/235 [==============================] - 0s 137us/step - loss: 0.1122 - accuracy: 0.9532 - val_loss: 0.0693 - val_accuracy: 0.9828\n",
      "Epoch 110/150\n",
      "235/235 [==============================] - 0s 124us/step - loss: 0.0891 - accuracy: 0.9660 - val_loss: 0.0725 - val_accuracy: 0.9828\n",
      "Epoch 111/150\n",
      "235/235 [==============================] - 0s 139us/step - loss: 0.0942 - accuracy: 0.9617 - val_loss: 0.0708 - val_accuracy: 0.9828\n",
      "Epoch 112/150\n",
      "235/235 [==============================] - 0s 134us/step - loss: 0.0849 - accuracy: 0.9745 - val_loss: 0.0713 - val_accuracy: 0.9828\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 138us/step - loss: 0.1053 - accuracy: 0.9617 - val_loss: 0.0711 - val_accuracy: 0.9914\n",
      "Epoch 114/150\n",
      "235/235 [==============================] - 0s 133us/step - loss: 0.0909 - accuracy: 0.9745 - val_loss: 0.0697 - val_accuracy: 0.9914\n",
      "Epoch 115/150\n",
      "235/235 [==============================] - 0s 141us/step - loss: 0.1031 - accuracy: 0.9617 - val_loss: 0.0681 - val_accuracy: 0.9914\n",
      "Epoch 116/150\n",
      "235/235 [==============================] - 0s 125us/step - loss: 0.0779 - accuracy: 0.9787 - val_loss: 0.0645 - val_accuracy: 0.9914\n",
      "Epoch 117/150\n",
      "235/235 [==============================] - 0s 153us/step - loss: 0.1118 - accuracy: 0.9574 - val_loss: 0.0679 - val_accuracy: 0.9914\n",
      "Epoch 118/150\n",
      "235/235 [==============================] - 0s 116us/step - loss: 0.0848 - accuracy: 0.9702 - val_loss: 0.0699 - val_accuracy: 0.9914\n",
      "Epoch 119/150\n",
      "235/235 [==============================] - 0s 130us/step - loss: 0.0865 - accuracy: 0.9617 - val_loss: 0.0721 - val_accuracy: 0.9828\n",
      "Epoch 120/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.0901 - accuracy: 0.9617 - val_loss: 0.0692 - val_accuracy: 0.9828\n",
      "Epoch 121/150\n",
      "235/235 [==============================] - 0s 118us/step - loss: 0.0717 - accuracy: 0.9745 - val_loss: 0.0693 - val_accuracy: 0.9828\n",
      "Epoch 122/150\n",
      "235/235 [==============================] - 0s 114us/step - loss: 0.0861 - accuracy: 0.9745 - val_loss: 0.0701 - val_accuracy: 0.9828\n",
      "Epoch 123/150\n",
      "235/235 [==============================] - 0s 105us/step - loss: 0.0836 - accuracy: 0.9702 - val_loss: 0.0657 - val_accuracy: 0.9828\n",
      "Epoch 124/150\n",
      "235/235 [==============================] - 0s 152us/step - loss: 0.0822 - accuracy: 0.9787 - val_loss: 0.0592 - val_accuracy: 0.9914\n",
      "Epoch 125/150\n",
      "235/235 [==============================] - 0s 116us/step - loss: 0.0690 - accuracy: 0.9830 - val_loss: 0.0582 - val_accuracy: 0.9914\n",
      "Epoch 126/150\n",
      "235/235 [==============================] - 0s 117us/step - loss: 0.0726 - accuracy: 0.9830 - val_loss: 0.0582 - val_accuracy: 0.9914\n",
      "Epoch 127/150\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0769 - accuracy: 0.9787 - val_loss: 0.0600 - val_accuracy: 0.9914\n",
      "Epoch 128/150\n",
      "235/235 [==============================] - 0s 120us/step - loss: 0.1183 - accuracy: 0.9489 - val_loss: 0.0624 - val_accuracy: 0.9914\n",
      "Epoch 129/150\n",
      "235/235 [==============================] - 0s 128us/step - loss: 0.0735 - accuracy: 0.9787 - val_loss: 0.0646 - val_accuracy: 0.9914\n",
      "Epoch 130/150\n",
      "235/235 [==============================] - 0s 126us/step - loss: 0.0901 - accuracy: 0.9702 - val_loss: 0.0664 - val_accuracy: 0.9914\n",
      "Epoch 131/150\n",
      "235/235 [==============================] - 0s 143us/step - loss: 0.0893 - accuracy: 0.9787 - val_loss: 0.0648 - val_accuracy: 0.9914\n",
      "Epoch 132/150\n",
      "235/235 [==============================] - 0s 104us/step - loss: 0.0956 - accuracy: 0.9617 - val_loss: 0.0667 - val_accuracy: 0.9914\n",
      "Epoch 133/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.0702 - accuracy: 0.9830 - val_loss: 0.0661 - val_accuracy: 0.9914\n",
      "Epoch 134/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.0710 - accuracy: 0.9872 - val_loss: 0.0661 - val_accuracy: 0.9914\n",
      "Epoch 135/150\n",
      "235/235 [==============================] - 0s 140us/step - loss: 0.0781 - accuracy: 0.9617 - val_loss: 0.0630 - val_accuracy: 0.9914\n",
      "Epoch 136/150\n",
      "235/235 [==============================] - 0s 136us/step - loss: 0.0861 - accuracy: 0.9745 - val_loss: 0.0639 - val_accuracy: 0.9914\n",
      "Epoch 137/150\n",
      "235/235 [==============================] - 0s 148us/step - loss: 0.0767 - accuracy: 0.9872 - val_loss: 0.0666 - val_accuracy: 0.9914\n",
      "Epoch 138/150\n",
      "235/235 [==============================] - 0s 154us/step - loss: 0.0796 - accuracy: 0.9787 - val_loss: 0.0684 - val_accuracy: 0.9914\n",
      "Epoch 139/150\n",
      "235/235 [==============================] - 0s 139us/step - loss: 0.0852 - accuracy: 0.9660 - val_loss: 0.0649 - val_accuracy: 0.9914\n",
      "Epoch 140/150\n",
      "235/235 [==============================] - 0s 152us/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.0647 - val_accuracy: 0.9914\n",
      "Epoch 141/150\n",
      "235/235 [==============================] - 0s 134us/step - loss: 0.0713 - accuracy: 0.9745 - val_loss: 0.0654 - val_accuracy: 0.9914\n",
      "Epoch 142/150\n",
      "235/235 [==============================] - 0s 142us/step - loss: 0.0881 - accuracy: 0.9532 - val_loss: 0.0688 - val_accuracy: 0.9914\n",
      "Epoch 143/150\n",
      "235/235 [==============================] - 0s 139us/step - loss: 0.0727 - accuracy: 0.9702 - val_loss: 0.0703 - val_accuracy: 0.9914\n",
      "Epoch 144/150\n",
      "235/235 [==============================] - 0s 145us/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0696 - val_accuracy: 0.9914\n",
      "Epoch 145/150\n",
      "235/235 [==============================] - 0s 138us/step - loss: 0.0899 - accuracy: 0.9745 - val_loss: 0.0672 - val_accuracy: 0.9914\n",
      "Epoch 146/150\n",
      "235/235 [==============================] - 0s 130us/step - loss: 0.0795 - accuracy: 0.9787 - val_loss: 0.0653 - val_accuracy: 0.9828\n",
      "Epoch 147/150\n",
      "235/235 [==============================] - 0s 144us/step - loss: 0.0685 - accuracy: 0.9745 - val_loss: 0.0644 - val_accuracy: 0.9914\n",
      "Epoch 148/150\n",
      "235/235 [==============================] - 0s 119us/step - loss: 0.0737 - accuracy: 0.9830 - val_loss: 0.0650 - val_accuracy: 0.9914\n",
      "Epoch 149/150\n",
      "235/235 [==============================] - 0s 119us/step - loss: 0.0663 - accuracy: 0.9830 - val_loss: 0.0664 - val_accuracy: 0.9914\n",
      "Epoch 150/150\n",
      "235/235 [==============================] - 0s 131us/step - loss: 0.0720 - accuracy: 0.9702 - val_loss: 0.0672 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26931933808>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
